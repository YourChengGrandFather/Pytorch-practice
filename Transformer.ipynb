{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9a62e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a553aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d00bc9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class AddNorm(nn.Module):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1aa3094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\"\"\"\n",
    "    # X:(batch_size，查询的个数,“键－值”对的个数)\n",
    "    print('valid_lens.dim() == 1:', valid_lens.dim() == 1)\n",
    "    print('valid_lens', valid_lens)\n",
    "    print('valid_lens_shape', valid_lens.shape)\n",
    "    # X:3D张量，valid_lens:1D或2D张量\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
    "        print('masked_softmax_valid_lens', valid_lens, len(valid_lens))\n",
    "        X = d2l.sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
    "                              value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3e8a6f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力\n",
    "    Defined in :numref:`subsec_additive-attention`\"\"\"\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # queries的形状：(batch_size，查询的个数，d)\n",
    "    # keys的形状：(batch_size，“键－值”对的个数，d)\n",
    "    # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
    "    # valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\n",
    "    # scores:(batch_size，查询的个数,“键－值”对的个数)\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        print('queries', queries.shape)\n",
    "        print('DotProductAttention valid_lens', valid_lens)\n",
    "        d = queries.shape[-1]\n",
    "        # 设置transpose_b=True为了交换keys的最后两个维度\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "#         print('attention_weights', self.attention_weights)\n",
    "        print('valid_lens', valid_lens.shape)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "81aa6a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"多头注意力\n",
    "    Defined in :numref:`sec_multihead-attention`\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        # queries，keys，values的形状:\n",
    "        # (batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "        # valid_lens　的形状:\n",
    "        # (batch_size，)或(batch_size，查询的个数)\n",
    "        # 经过变换后，输出的queries，keys，values　的形状:\n",
    "        # (batch_size*num_heads，查询或者“键－值”对的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # 在轴0，将第一项（标量或者矢量）复制num_heads次，\n",
    "            # 然后如此复制第二项，然后诸如此类。\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0)\n",
    "\n",
    "        # output的形状:(batch_size*num_heads，查询的个数，\n",
    "        # num_hiddens/num_heads)\n",
    "#         print('queries', queries.shape)\n",
    "#         print('MultiHeadAttention valid_lens', valid_lens)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "\n",
    "        # output_concat的形状:(batch_size，查询的个数，num_hiddens)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)\n",
    "\n",
    "def transpose_qkv(X, num_heads):\n",
    "    \"\"\"为了多注意力头的并行计算而变换形状\n",
    "    Defined in :numref:`sec_multihead-attention`\"\"\"\n",
    "    # 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)\n",
    "    # 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，\n",
    "    # num_hiddens/num_heads)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "\n",
    "    # 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,\n",
    "    # num_hiddens/num_heads)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "\n",
    "    # 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,\n",
    "    # num_hiddens/num_heads)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"逆转transpose_qkv函数的操作\n",
    "    Defined in :numref:`sec_multihead-attention`\"\"\"\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "32231cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"transformer编码器块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n",
    "            use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(\n",
    "            ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "#         print('valid_lens2', valid_lens)\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "9b2f492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class TransformerEncoder(d2l.Encoder):\n",
    "    \"\"\"transformer编码器\"\"\"\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, use_bias))\n",
    "\n",
    "    def forward(self, X, valid_lens, *args):\n",
    "        # 因为位置编码值在-1和1之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n",
    "        # 然后再与位置编码相加。\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[\n",
    "                i] = blk.attention.attention.attention_weights\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "93edc69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中第i个块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = d2l.MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,\n",
    "                                   num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        # [enc_outputs, enc_valid_lens, [None] * self.num_layers]\n",
    "        # 训练阶段，输出序列的所有词元都在同一时间处理，\n",
    "        # 因此state[2][self.i]初始化为None。\n",
    "        # 预测阶段，输出序列是通过词元一个接着一个解码的，\n",
    "        # 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if 1:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            print('batch_size', batch_size)\n",
    "            # dec_valid_lens的开头:(batch_size,num_steps),\n",
    "            # 其中每一行是[1,2,...,num_steps]\n",
    "            dec_valid_lens = torch.arange(\n",
    "                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "        print('X.shape', X.shape)\n",
    "        print('dec_valid_lens2', dec_valid_lens, dec_valid_lens.shape)\n",
    "        # 自注意力\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        # 编码器－解码器注意力。\n",
    "        # enc_outputs的开头:(batch_size,num_steps,num_hiddens)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "238dfe89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries torch.Size([16, 100, 3])\n",
      "DotProductAttention valid_lens tensor([3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "valid_lens_shape torch.Size([16])\n",
      "masked_softmax_valid_lens tensor([3, 3, 3,  ..., 2, 2, 2]) 1600\n",
      "valid_lens torch.Size([16])\n",
      "batch_size 2\n",
      "X.shape torch.Size([2, 100, 24])\n",
      "dec_valid_lens2 tensor([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "          15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "          29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "          43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "          57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "          71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "          85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "          99, 100],\n",
      "        [  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "          15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "          29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "          43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "          57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "          71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "          85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "          99, 100]]) torch.Size([2, 100])\n",
      "queries torch.Size([16, 100, 3])\n",
      "DotProductAttention valid_lens tensor([[  1,   2,   3,  ...,  98,  99, 100],\n",
      "        [  1,   2,   3,  ...,  98,  99, 100],\n",
      "        [  1,   2,   3,  ...,  98,  99, 100],\n",
      "        ...,\n",
      "        [  1,   2,   3,  ...,  98,  99, 100],\n",
      "        [  1,   2,   3,  ...,  98,  99, 100],\n",
      "        [  1,   2,   3,  ...,  98,  99, 100]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[  1,   2,   3,  ...,  98,  99, 100],\n",
      "        [  1,   2,   3,  ...,  98,  99, 100],\n",
      "        [  1,   2,   3,  ...,  98,  99, 100],\n",
      "        ...,\n",
      "        [  1,   2,   3,  ...,  98,  99, 100],\n",
      "        [  1,   2,   3,  ...,  98,  99, 100],\n",
      "        [  1,   2,   3,  ...,  98,  99, 100]])\n",
      "valid_lens_shape torch.Size([16, 100])\n",
      "masked_softmax_valid_lens tensor([  1,   2,   3,  ...,  98,  99, 100]) 1600\n",
      "valid_lens torch.Size([16, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_blk = DecoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5, 0)\n",
    "decoder_blk.eval()\n",
    "X = torch.ones((2, 100, 24))\n",
    "# valid_lens=[1,2]\n",
    "state = [encoder_blk(X, valid_lens), valid_lens, [None]]\n",
    "decoder_blk(X, state)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "402dee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(d2l.AttentionDecoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, i))\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            # 解码器自注意力权重\n",
    "            self._attention_weights[0][\n",
    "                i] = blk.attention1.attention.attention_weights\n",
    "            # “编码器－解码器”自注意力权重\n",
    "            self._attention_weights[1][\n",
    "                i] = blk.attention2.attention.attention_weights\n",
    "        return self.dense(X), state\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d250c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"编码器-解码器架构的基类\n",
    "    Defined in :numref:`sec_encoder-decoder`\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "47f2e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"训练序列到序列模型\n",
    "    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = d2l.MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                     xlim=[10, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = d2l.Timer()\n",
    "        metric = d2l.Accumulator(2)  # 训练损失总和，词元数量\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            print('X.shape', X.shape)\n",
    "            print('X_valid_len', X_valid_len)\n",
    "            print('X_valid_len', len(X_valid_len))\n",
    "            \n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                          device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # 强制教学\n",
    "#             print(dec_input)\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()\t# 损失函数的标量进行“反向传播”\n",
    "            d2l.grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "            break\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            animator.add(epoch + 1, (metric[0] / metric[1],))\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
    "        f'tokens/sec on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "95d01c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape torch.Size([64, 10])\n",
      "X_valid_len tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4,\n",
      "        4, 4, 5, 4, 3, 4, 5, 4, 4, 3, 4, 4, 5, 4, 4, 4])\n",
      "X_valid_len 64\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([4, 4, 4,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([4, 4, 4,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "X.shape torch.Size([64, 10])\n",
      "X_valid_len tensor([3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4])\n",
      "X_valid_len 64\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([3, 3, 3,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([3, 3, 3,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "X.shape torch.Size([64, 10])\n",
      "X_valid_len tensor([4, 3, 4, 4, 5, 4, 4, 5, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 5, 4, 4, 5])\n",
      "X_valid_len 64\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([4, 4, 4,  ..., 5, 5, 5]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([4, 4, 4,  ..., 5, 5, 5]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "X.shape torch.Size([64, 10])\n",
      "X_valid_len tensor([5, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 4, 4, 4, 4, 5, 4, 5, 4, 3, 5, 4, 5, 4, 4, 5])\n",
      "X_valid_len 64\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 3, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 3, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([5, 5, 5,  ..., 5, 5, 5]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 3, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 3, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([5, 5, 5,  ..., 5, 5, 5]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "X.shape torch.Size([64, 10])\n",
      "X_valid_len tensor([4, 5, 4, 4, 4, 5, 4, 4, 3, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4])\n",
      "X_valid_len 64\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([4, 4, 4,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_lens tensor([4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([4, 4, 4,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "X.shape torch.Size([64, 10])\n",
      "X_valid_len tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 5, 5, 4, 4,\n",
      "        4, 4, 4, 4, 3, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 3, 4, 4, 4, 4, 4, 5, 4, 4, 4, 5, 4, 4, 4, 4])\n",
      "X_valid_len 64\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([4, 4, 4,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([4, 4, 4,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "X.shape torch.Size([64, 10])\n",
      "X_valid_len tensor([5, 4, 5, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 5, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "X_valid_len 64\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([5, 5, 5,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([5, 5, 5,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "X.shape torch.Size([64, 10])\n",
      "X_valid_len tensor([4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 5, 4, 4,\n",
      "        4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4])\n",
      "X_valid_len 64\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([4, 4, 4,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([4, 4, 4,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "X.shape torch.Size([64, 10])\n",
      "X_valid_len tensor([3, 4, 4, 5, 4, 4, 3, 4, 4, 3, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 4, 4, 5, 4, 4, 4, 5, 5, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 3, 4,\n",
      "        4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 5, 5, 4])\n",
      "X_valid_len 64\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([3, 3, 3,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([3, 3, 3,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape torch.Size([64, 10])\n",
      "X_valid_len tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 5, 5, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 3, 4, 4, 3, 5, 5, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 5, 5, 4, 4, 4, 4, 4, 4, 4])\n",
      "X_valid_len 64\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([4, 4, 4,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens.dim() == 1: True\n",
      "valid_lens tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])\n",
      "valid_lens_shape torch.Size([256])\n",
      "masked_softmax_valid_lens tensor([4, 4, 4,  ..., 4, 4, 4]) 2560\n",
      "valid_lens torch.Size([256])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n",
      "batch_size 64\n",
      "X.shape torch.Size([64, 10, 32])\n",
      "dec_valid_lens2 tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]]) torch.Size([64, 10])\n",
      "queries torch.Size([256, 10, 8])\n",
      "DotProductAttention valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens.dim() == 1: False\n",
      "valid_lens tensor([[ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        ...,\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10],\n",
      "        [ 1,  2,  3,  ...,  8,  9, 10]])\n",
      "valid_lens_shape torch.Size([256, 10])\n",
      "masked_softmax_valid_lens tensor([ 1,  2,  3,  ...,  8,  9, 10]) 2560\n",
      "valid_lens torch.Size([256, 10])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [234]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m decoder \u001b[38;5;241m=\u001b[39m TransformerDecoder(\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mlen\u001b[39m(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n\u001b[1;32m     15\u001b[0m     norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n\u001b[1;32m     16\u001b[0m     num_layers, dropout)\n\u001b[1;32m     17\u001b[0m net \u001b[38;5;241m=\u001b[39m EncoderDecoder(encoder, decoder)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mtrain_seq2seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [233]\u001b[0m, in \u001b[0;36mtrain_seq2seq\u001b[0;34m(net, data_iter, lr, num_epochs, tgt_vocab, device)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 43\u001b[0m         \u001b[43manimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m metric[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m timer\u001b[38;5;241m.\u001b[39mstop()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens/sec on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/d2l/torch.py:326\u001b[0m, in \u001b[0;36mAnimator.add\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(x, y, fmt)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_axes()\n\u001b[0;32m--> 326\u001b[0m \u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m display\u001b[38;5;241m.\u001b[39mclear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/formatters.py:178\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    176\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/formatters.py:222\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/formatters.py:339\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    341\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/pylabtools.py:151\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    149\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 151\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backend_bases.py:2319\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2317\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2319\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2320\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2321\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2322\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2323\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2324\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2325\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backend_bases.py:1648\u001b[0m, in \u001b[0;36m_check_savefig_extra_args.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_deprecated(\n\u001b[1;32m   1641\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3.3\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39mname, removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3.6\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1642\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m() got unexpected keyword argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1643\u001b[0m                 \u001b[38;5;241m+\u001b[39m arg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m which is no longer supported as of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1644\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m and will become an error \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1645\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1646\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(arg)\n\u001b[0;32m-> 1648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:386\u001b[0m, in \u001b[0;36mdelete_parameter.<locals>.wrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39minner_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_kwargs):\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inner_args) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m name_idx \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m inner_kwargs:\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;66;03m# Early return in the simple, non-deprecated case (much faster than\u001b[39;00m\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;66;03m# calling bind()).\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m     arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39minner_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_kwargs)\u001b[38;5;241m.\u001b[39marguments\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_varargs \u001b[38;5;129;01mand\u001b[39;00m arguments\u001b[38;5;241m.\u001b[39mget(name):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:412\u001b[0m, in \u001b[0;36mdelete_parameter.<locals>.wrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     deprecation_addendum \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf any parameter follows \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m, they should be passed as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeyword, not positionally.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    405\u001b[0m     warn_deprecated(\n\u001b[1;32m    406\u001b[0m         since,\n\u001b[1;32m    407\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrepr\u001b[39m(name),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m                  \u001b[38;5;28;01melse\u001b[39;00m deprecation_addendum,\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_svg.py:1333\u001b[0m, in \u001b[0;36mFigureCanvasSVG.print_svg\u001b[0;34m(self, filename, dpi, bbox_inches_restore, metadata, *args)\u001b[0m\n\u001b[1;32m   1328\u001b[0m w, h \u001b[38;5;241m=\u001b[39m width \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m72\u001b[39m, height \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m72\u001b[39m\n\u001b[1;32m   1329\u001b[0m renderer \u001b[38;5;241m=\u001b[39m MixedModeRenderer(\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, width, height, dpi,\n\u001b[1;32m   1331\u001b[0m     RendererSVG(w, h, fh, image_dpi\u001b[38;5;241m=\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata),\n\u001b[1;32m   1332\u001b[0m     bbox_inches_restore\u001b[38;5;241m=\u001b[39mbbox_inches_restore)\n\u001b[0;32m-> 1333\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m renderer\u001b[38;5;241m.\u001b[39mfinalize()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/artist.py:73\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 73\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     75\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/figure.py:2810\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2807\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 2810\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[1;32m   2814\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_base.py:3082\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3079\u001b[0m         a\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m   3080\u001b[0m     renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n\u001b[0;32m-> 3082\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3085\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3086\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/artist.py:50\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axis.py:1170\u001b[0m, in \u001b[0;36mAxis.draw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1163\u001b[0m     tick\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;66;03m# scale up the axis label box to also find the neighbors, not\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;66;03m# just the tick labels that actually overlap note we need a\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;66;03m# *copy* of the axis label box because we don't want to scale\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;66;03m# the actual bbox\u001b[39;00m\n\u001b[0;32m-> 1170\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_label_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_offset_text_position(ticklabelBoxes, ticklabelBoxes2)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axis.py:2083\u001b[0m, in \u001b[0;36mXAxis._update_label_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2079\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2081\u001b[0m \u001b[38;5;66;03m# get bounding boxes for this axis and any siblings\u001b[39;00m\n\u001b[1;32m   2082\u001b[0m \u001b[38;5;66;03m# that have been set by `fig.align_xlabels()`\u001b[39;00m\n\u001b[0;32m-> 2083\u001b[0m bboxes, bboxes2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tick_boxes_siblings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2085\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mget_position()\n\u001b[1;32m   2086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_position \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottom\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axis.py:1880\u001b[0m, in \u001b[0;36mAxis._get_tick_boxes_siblings\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1878\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mget_siblings(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes):\n\u001b[1;32m   1879\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(ax, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1880\u001b[0m     ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1881\u001b[0m     tlb, tlb2 \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39m_get_tick_bboxes(ticks_to_draw, renderer)\n\u001b[1;32m   1882\u001b[0m     bboxes\u001b[38;5;241m.\u001b[39mextend(tlb)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axis.py:1045\u001b[0m, in \u001b[0;36mAxis._update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_ticks\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;124;03m    Update ticks (position and labels) using the current data interval of\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;124;03m    the axes.  Return the list of ticks that will be drawn.\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1045\u001b[0m     major_locs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_majorticklocs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1046\u001b[0m     major_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmajor\u001b[38;5;241m.\u001b[39mformatter\u001b[38;5;241m.\u001b[39mformat_ticks(major_locs)\n\u001b[1;32m   1047\u001b[0m     major_ticks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_major_ticks(\u001b[38;5;28mlen\u001b[39m(major_locs))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axis.py:1277\u001b[0m, in \u001b[0;36mAxis.get_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_majorticklocs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;124;03m\"\"\"Return this Axis' major tick locations in data coordinates.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmajor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/ticker.py:2114\u001b[0m, in \u001b[0;36mMaxNLocator.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2113\u001b[0m     vmin, vmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\u001b[38;5;241m.\u001b[39mget_view_interval()\n\u001b[0;32m-> 2114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/ticker.py:2122\u001b[0m, in \u001b[0;36mMaxNLocator.tick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2119\u001b[0m     vmin \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mvmax\n\u001b[1;32m   2120\u001b[0m vmin, vmax \u001b[38;5;241m=\u001b[39m mtransforms\u001b[38;5;241m.\u001b[39mnonsingular(\n\u001b[1;32m   2121\u001b[0m     vmin, vmax, expander\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-13\u001b[39m, tiny\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-14\u001b[39m)\n\u001b[0;32m-> 2122\u001b[0m locs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2124\u001b[0m prune \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prune\n\u001b[1;32m   2125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prune \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/ticker.py:2061\u001b[0m, in \u001b[0;36mMaxNLocator._raw_ticks\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nbins \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   2060\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2061\u001b[0m         nbins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tick_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   2062\u001b[0m                         \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_n_ticks \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m9\u001b[39m)\n\u001b[1;32m   2063\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2064\u001b[0m         nbins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axis.py:2263\u001b[0m, in \u001b[0;36mXAxis.get_tick_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_tick_space\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2262\u001b[0m     ends \u001b[38;5;241m=\u001b[39m mtransforms\u001b[38;5;241m.\u001b[39mBbox\u001b[38;5;241m.\u001b[39mfrom_bounds(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 2263\u001b[0m     ends \u001b[38;5;241m=\u001b[39m ends\u001b[38;5;241m.\u001b[39mtransformed(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransAxes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\n\u001b[1;32m   2264\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi_scale_trans\u001b[49m)\n\u001b[1;32m   2265\u001b[0m     length \u001b[38;5;241m=\u001b[39m ends\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m72\u001b[39m\n\u001b[1;32m   2266\u001b[0m     \u001b[38;5;66;03m# There is a heuristic here that the aspect ratio of tick text\u001b[39;00m\n\u001b[1;32m   2267\u001b[0m     \u001b[38;5;66;03m# is no more than 3:1\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/transforms.py:1459\u001b[0m, in \u001b[0;36mTransform.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m remainder, sub_tree \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_break_from_left_to_right():\n\u001b[0;32m-> 1459\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msub_tree\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m:\n\u001b[1;32m   1460\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m remainder\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m remainder, sub_tree \u001b[38;5;129;01min\u001b[39;00m other\u001b[38;5;241m.\u001b[39m_iter_break_from_left_to_right():\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/transforms.py:1793\u001b[0m, in \u001b[0;36mAffineBase.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m   1792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(other, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_affine\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(other, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1793\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mall\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2450\u001b[0m, in \u001b[0;36mall\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2367\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_all_dispatcher)\n\u001b[1;32m   2368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2369\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2370\u001b[0m \u001b[38;5;124;03m    Test whether all array elements along a given axis evaluate to True.\u001b[39;00m\n\u001b[1;32m   2371\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2448\u001b[0m \n\u001b[1;32m   2449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_and\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"262.1875pt\" height=\"184.175813pt\" viewBox=\"0 0 262.1875 184.175813\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-10-08T21:04:03.934949</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 184.175813 \n",
       "L 262.1875 184.175813 \n",
       "L 262.1875 0 \n",
       "L 0 0 \n",
       "L 0 184.175813 \n",
       "z\n",
       "\" style=\"fill: none\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 50.14375 146.619563 \n",
       "L 245.44375 146.619563 \n",
       "L 245.44375 10.719563 \n",
       "L 50.14375 10.719563 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 91.259539 146.619563 \n",
       "L 91.259539 10.719563 \n",
       "\" clip-path=\"url(#p9732f2f6b4)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m4867738ac1\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4867738ac1\" x=\"91.259539\" y=\"146.619563\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(84.897039 161.218001)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 142.654276 146.619563 \n",
       "L 142.654276 10.719563 \n",
       "\" clip-path=\"url(#p9732f2f6b4)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4867738ac1\" x=\"142.654276\" y=\"146.619563\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(133.110526 161.218001)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 194.049013 146.619563 \n",
       "L 194.049013 10.719563 \n",
       "\" clip-path=\"url(#p9732f2f6b4)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4867738ac1\" x=\"194.049013\" y=\"146.619563\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 150 -->\n",
       "      <g transform=\"translate(184.505263 161.218001)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 245.44375 146.619563 \n",
       "L 245.44375 10.719563 \n",
       "\" clip-path=\"url(#p9732f2f6b4)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4867738ac1\" x=\"245.44375\" y=\"146.619563\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(235.9 161.218001)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_5\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(132.565625 174.896126)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 50.14375 124.349316 \n",
       "L 245.44375 124.349316 \n",
       "\" clip-path=\"url(#p9732f2f6b4)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <defs>\n",
       "       <path id=\"mc21a7736d4\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc21a7736d4\" x=\"50.14375\" y=\"124.349316\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0.30 -->\n",
       "      <g transform=\"translate(20.878125 128.148534)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 50.14375 86.56595 \n",
       "L 245.44375 86.56595 \n",
       "\" clip-path=\"url(#p9732f2f6b4)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc21a7736d4\" x=\"50.14375\" y=\"86.56595\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.32 -->\n",
       "      <g transform=\"translate(20.878125 90.365169)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 50.14375 48.782584 \n",
       "L 245.44375 48.782584 \n",
       "\" clip-path=\"url(#p9732f2f6b4)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc21a7736d4\" x=\"50.14375\" y=\"48.782584\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.34 -->\n",
       "      <g transform=\"translate(20.878125 52.581803)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 50.14375 10.999219 \n",
       "L 245.44375 10.999219 \n",
       "\" clip-path=\"url(#p9732f2f6b4)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc21a7736d4\" x=\"50.14375\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.36 -->\n",
       "      <g transform=\"translate(20.878125 14.798438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_10\">\n",
       "     <!-- loss -->\n",
       "     <g transform=\"translate(14.798437 88.327376)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"27.783203\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"88.964844\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"141.064453\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_17\">\n",
       "    <path d=\"M 50.14375 16.896836 \n",
       "L 60.422697 140.44229 \n",
       "\" clip-path=\"url(#p9732f2f6b4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 50.14375 146.619563 \n",
       "L 50.14375 10.719563 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 245.44375 146.619563 \n",
       "L 245.44375 10.719563 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 50.14375 146.619563 \n",
       "L 245.44375 146.619563 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 50.14375 10.719563 \n",
       "L 245.44375 10.719563 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p9732f2f6b4\">\n",
       "   <rect x=\"50.14375\" y=\"10.719563\" width=\"195.3\" height=\"135.9\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10\n",
    "lr, num_epochs, device = 0.005, 200, d2l.try_gpu()\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)\n",
    "\n",
    "encoder = TransformerEncoder(\n",
    "    len(src_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "decoder = TransformerDecoder(\n",
    "    len(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "net = EncoderDecoder(encoder, decoder)\n",
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b5bf36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c75374e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
