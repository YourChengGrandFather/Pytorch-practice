{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f39ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01dfa978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=8):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        # 利用1x1卷积代替全连接\n",
    "        self.fc1   = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2   = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        print('x',x.shape)\n",
    "        print('avg_pool', self.avg_pool(x).shape)\n",
    "        print('max_pool', self.max_pool(x).shape)\n",
    "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
    "        out = avg_out + max_out\n",
    "        print('out', out.shape)\n",
    "        print('result', self.sigmoid(out).shape)\n",
    "        return self.sigmoid(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cbec442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([2, 512, 28, 28])\n",
      "avg_pool torch.Size([2, 512, 1, 1])\n",
      "max_pool torch.Size([2, 512, 1, 1])\n",
      "out torch.Size([2, 512, 1, 1])\n",
      "result torch.Size([2, 512, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3882]],\n",
       "\n",
       "         [[0.3906]],\n",
       "\n",
       "         [[0.5325]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.5554]],\n",
       "\n",
       "         [[0.5454]],\n",
       "\n",
       "         [[0.4556]]],\n",
       "\n",
       "\n",
       "        [[[0.3882]],\n",
       "\n",
       "         [[0.3906]],\n",
       "\n",
       "         [[0.5325]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.5554]],\n",
       "\n",
       "         [[0.5454]],\n",
       "\n",
       "         [[0.4556]]]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2,512,28,28)\n",
    "b,c,w,h = x.shape\n",
    "channelAttention = ChannelAttention(c)\n",
    "channelAttention(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df58e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        print('x',x.shape)\n",
    "        print('avg_pool', avg_out.shape)\n",
    "        print('max_pool', avg_out.shape)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        print('cat_x', x.shape)\n",
    "        x = self.conv1(x)\n",
    "        print('cat_x', x.shape)\n",
    "        return self.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3694206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([2, 512, 28, 28])\n",
      "avg_pool torch.Size([2, 1, 28, 28])\n",
      "max_pool torch.Size([2, 1, 28, 28])\n",
      "cat_x torch.Size([2, 2, 28, 28])\n",
      "cat_x torch.Size([2, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5344, 0.5581, 0.5547,  ..., 0.5775, 0.5661, 0.5444],\n",
       "          [0.5531, 0.5956, 0.5937,  ..., 0.6075, 0.5751, 0.5679],\n",
       "          [0.4813, 0.5607, 0.5571,  ..., 0.5881, 0.5915, 0.5816],\n",
       "          ...,\n",
       "          [0.4418, 0.5045, 0.5202,  ..., 0.6416, 0.6296, 0.6327],\n",
       "          [0.4493, 0.5051, 0.5097,  ..., 0.6030, 0.6108, 0.5946],\n",
       "          [0.4400, 0.4956, 0.5074,  ..., 0.6156, 0.6322, 0.6198]]],\n",
       "\n",
       "\n",
       "        [[[0.5344, 0.5581, 0.5547,  ..., 0.5775, 0.5661, 0.5444],\n",
       "          [0.5531, 0.5956, 0.5937,  ..., 0.6075, 0.5751, 0.5679],\n",
       "          [0.4813, 0.5607, 0.5571,  ..., 0.5881, 0.5915, 0.5816],\n",
       "          ...,\n",
       "          [0.4418, 0.5045, 0.5202,  ..., 0.6416, 0.6296, 0.6327],\n",
       "          [0.4493, 0.5051, 0.5097,  ..., 0.6030, 0.6108, 0.5946],\n",
       "          [0.4400, 0.4956, 0.5074,  ..., 0.6156, 0.6322, 0.6198]]]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2,512,28,28)\n",
    "b,c,w,h = x.shape\n",
    "spatialAttention = SpatialAttention()\n",
    "spatialAttention(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e217fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cbam_block(nn.Module):\n",
    "    def __init__(self, channel, ratio=8, kernel_size=7):\n",
    "        super(cbam_block, self).__init__()\n",
    "        self.channelattention = ChannelAttention(channel, ratio=ratio)\n",
    "        self.spatialattention = SpatialAttention(kernel_size=kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.channelattention(x)\n",
    "        print('xxx',x.shape)\n",
    "        x = x * self.spatialattention(x)\n",
    "        print('xxx2',x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f604e9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "cbam_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0892edd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
