{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b601e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a99091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class Seq2SeqEncoder(d2l.Encoder):\n",
    "    \"\"\"用于序列到序列学习的循环神经网络编码器\"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
    "        # 嵌入层\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        # 输出'X'的形状：(batch_size,num_steps,embed_size)\n",
    "#         print('xxxx',X.shape)\n",
    "        X = self.embedding(X)\n",
    "#         print('xxxx2',X.shape)\n",
    "        # 在循环神经网络模型中，第一个轴对应于时间步\n",
    "        X = X.permute(1, 0, 2)\n",
    "        # 如果未提及状态，则默认为0\n",
    "        output, state = self.rnn(X)\n",
    "        # output的形状:(num_steps,batch_size,num_hiddens)\n",
    "        # state的形状:(num_layers,batch_size,num_hiddens)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a7bfa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 4, 16])\n",
      "torch.Size([2, 4, 16])\n"
     ]
    }
   ],
   "source": [
    "encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                         num_layers=2)\n",
    "encoder.eval()\n",
    "X = torch.zeros((4, 7), dtype=torch.long)\n",
    "output, state = encoder(X)\n",
    "print(output.shape)\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16a6482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Seq2SeqDecoder(d2l.Decoder):\n",
    "#     \"\"\"用于序列到序列学习的循环神经网络解码器\"\"\"\n",
    "#     def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "#                  dropout=0, **kwargs):\n",
    "#         super(Seq2SeqDecoder, self).__init__(**kwargs)\n",
    "#         self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "#         self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,\n",
    "#                           dropout=dropout)\n",
    "#         self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "#     def init_state(self, enc_outputs, *args):\n",
    "#         return enc_outputs[1]\n",
    "\n",
    "#     def forward(self, X, state):\n",
    "#         # 输出'X'的形状：(batch_size,num_steps,embed_size)\n",
    "#         print('X',X.shape)\n",
    "#         X = self.embedding(X).permute(1, 0, 2)\n",
    "#         print('X',X.shape)\n",
    "#         # 广播context，使其具有与X相同的num_steps\n",
    "#         print('state[-1]',state[-1].shape)\n",
    "#         context = state[-1].repeat(X.shape[0], 1, 1)\n",
    "#         print('context',context.shape)\n",
    "#         X_and_context = torch.cat((X, context), 2)\n",
    "#         print('X_and_context', X_and_context.shape)\n",
    "#         output, state = self.rnn(X_and_context, state)\n",
    "#         print('output', output.shape)\n",
    "#         output = self.dense(output).permute(1, 0, 2)\n",
    "#         # output的形状:(batch_size,num_steps,vocab_size)\n",
    "#         # state的形状:(num_layers,batch_size,num_hiddens)\n",
    "#         return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b669871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(d2l.Decoder):\n",
    "    \"\"\"用于序列到序列学习的循环神经网络解码器\"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqDecoder, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        return enc_outputs[1]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # 输出'X'的形状：(num_steps,batch_size,embed_size)\n",
    "        X = self.embedding(X).permute(1, 0, 2)\n",
    "        print('X', X.shape)\n",
    "        # 广播context，使其具有与X相同的num_steps\n",
    "        # 广播context的形状：[]\n",
    "        context = state[-1].repeat(X.shape[0], 1, 1)\n",
    "        X_and_context = torch.cat((X, context), 2)\n",
    "        output, state = self.rnn(X_and_context, state)\n",
    "        output = self.dense(output).permute(1, 0, 2)\n",
    "        # output的形状:(batch_size,num_steps,vocab_size)\n",
    "        # state的形状:(num_layers,batch_size,num_hiddens)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da8049ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state torch.Size([2, 4, 16])\n",
      "X torch.Size([7, 4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 10]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                         num_layers=2)\n",
    "decoder.eval()\n",
    "state = decoder.init_state(encoder(X))\n",
    "print('state',state.shape)\n",
    "output, state = decoder(X, state)\n",
    "output.shape, state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad7274f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [4, 5, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@save\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "X = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "sequence_mask(X, torch.tensor([1, 2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39aa52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"带遮蔽的softmax交叉熵损失函数\"\"\"\n",
    "    # pred的形状：(batch_size,num_steps,vocab_size)\n",
    "    # label的形状：(batch_size,num_steps)\n",
    "    # valid_len的形状：(batch_size,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction='none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac3b4543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 1.1513, 0.0000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = MaskedSoftmaxCELoss()\n",
    "loss(torch.ones(3, 4, 10), \n",
    "     torch.ones((3, 4), dtype=torch.long),\n",
    "     torch.tensor([4, 2, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea669f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"训练序列到序列模型\"\"\"\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                     xlim=[10, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = d2l.Timer()\n",
    "        metric = d2l.Accumulator(2)  # 训练损失总和，词元数量\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            print('y.shape',Y.shape)\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                          device=device).reshape(-1, 1)\n",
    "            print('bos.shape',bos.shape)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # 强制教学\n",
    "            print('dec_input',dec_input)\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()      # 损失函数的标量进行“反向传播”\n",
    "            d2l.grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            animator.add(epoch + 1, (metric[0] / metric[1],))\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
    "        f'tokens/sec on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cb21ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.019, 10640.8 tokens/sec on cpu\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"262.1875pt\" height=\"180.65625pt\" viewBox=\"0 0 262.1875 180.65625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-10-05T11:20:12.723733</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 180.65625 \n",
       "L 262.1875 180.65625 \n",
       "L 262.1875 0 \n",
       "L 0 0 \n",
       "L 0 180.65625 \n",
       "z\n",
       "\" style=\"fill: none\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 50.14375 143.1 \n",
       "L 245.44375 143.1 \n",
       "L 245.44375 7.2 \n",
       "L 50.14375 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 77.081681 143.1 \n",
       "L 77.081681 7.2 \n",
       "\" clip-path=\"url(#p9713c3fef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"mc6fbeb5072\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc6fbeb5072\" x=\"77.081681\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(70.719181 157.698438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 110.754095 143.1 \n",
       "L 110.754095 7.2 \n",
       "\" clip-path=\"url(#p9713c3fef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc6fbeb5072\" x=\"110.754095\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(101.210345 157.698438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 144.426509 143.1 \n",
       "L 144.426509 7.2 \n",
       "\" clip-path=\"url(#p9713c3fef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc6fbeb5072\" x=\"144.426509\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 150 -->\n",
       "      <g transform=\"translate(134.882759 157.698438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 178.098922 143.1 \n",
       "L 178.098922 7.2 \n",
       "\" clip-path=\"url(#p9713c3fef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc6fbeb5072\" x=\"178.098922\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(168.555172 157.698438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 211.771336 143.1 \n",
       "L 211.771336 7.2 \n",
       "\" clip-path=\"url(#p9713c3fef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc6fbeb5072\" x=\"211.771336\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 250 -->\n",
       "      <g transform=\"translate(202.227586 157.698438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 245.44375 143.1 \n",
       "L 245.44375 7.2 \n",
       "\" clip-path=\"url(#p9713c3fef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc6fbeb5072\" x=\"245.44375\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 300 -->\n",
       "      <g transform=\"translate(235.9 157.698438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(132.565625 171.376563)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 50.14375 117.89295 \n",
       "L 245.44375 117.89295 \n",
       "\" clip-path=\"url(#p9713c3fef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <defs>\n",
       "       <path id=\"m70958b5af4\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m70958b5af4\" x=\"50.14375\" y=\"117.89295\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.05 -->\n",
       "      <g transform=\"translate(20.878125 121.692168)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 50.14375 87.066999 \n",
       "L 245.44375 87.066999 \n",
       "\" clip-path=\"url(#p9713c3fef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m70958b5af4\" x=\"50.14375\" y=\"87.066999\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.10 -->\n",
       "      <g transform=\"translate(20.878125 90.866218)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 50.14375 56.241048 \n",
       "L 245.44375 56.241048 \n",
       "\" clip-path=\"url(#p9713c3fef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m70958b5af4\" x=\"50.14375\" y=\"56.241048\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.15 -->\n",
       "      <g transform=\"translate(20.878125 60.040267)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 50.14375 25.415098 \n",
       "L 245.44375 25.415098 \n",
       "\" clip-path=\"url(#p9713c3fef3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m70958b5af4\" x=\"50.14375\" y=\"25.415098\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.20 -->\n",
       "      <g transform=\"translate(20.878125 29.214317)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- loss -->\n",
       "     <g transform=\"translate(14.798437 84.807812)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"27.783203\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"88.964844\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"141.064453\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path d=\"M 50.14375 13.377273 \n",
       "L 56.878233 53.530367 \n",
       "L 63.612716 77.030213 \n",
       "L 70.347198 93.705874 \n",
       "L 77.081681 105.534717 \n",
       "L 83.816164 112.880268 \n",
       "L 90.550647 118.618282 \n",
       "L 97.285129 122.336576 \n",
       "L 104.019612 125.496294 \n",
       "L 110.754095 127.603814 \n",
       "L 117.488578 129.523524 \n",
       "L 124.22306 131.298808 \n",
       "L 130.957543 131.925726 \n",
       "L 137.692026 132.618463 \n",
       "L 144.426509 134.097803 \n",
       "L 151.160991 134.070232 \n",
       "L 157.895474 134.84295 \n",
       "L 164.629957 135.003864 \n",
       "L 171.36444 135.030731 \n",
       "L 178.098922 135.636242 \n",
       "L 184.833405 136.198717 \n",
       "L 191.567888 135.953279 \n",
       "L 198.302371 136.241671 \n",
       "L 205.036853 136.123368 \n",
       "L 211.771336 136.088303 \n",
       "L 218.505819 136.922727 \n",
       "L 225.240302 136.652521 \n",
       "L 231.974784 136.753007 \n",
       "L 238.709267 136.714202 \n",
       "L 245.44375 136.741458 \n",
       "\" clip-path=\"url(#p9713c3fef3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 50.14375 143.1 \n",
       "L 50.14375 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 245.44375 143.1 \n",
       "L 245.44375 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 50.14375 143.1 \n",
       "L 245.44375 143.1 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 50.14375 7.2 \n",
       "L 245.44375 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p9713c3fef3\">\n",
       "   <rect x=\"50.14375\" y=\"7.2\" width=\"195.3\" height=\"135.9\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs, device = 0.005, 300, d2l.try_gpu()\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)\n",
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers,\n",
    "                        dropout)\n",
    "decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers,\n",
    "                        dropout)\n",
    "net = d2l.EncoderDecoder(encoder, decoder)\n",
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a26a54ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    \"\"\"序列到序列模型的预测\"\"\"\n",
    "    # 在预测时将net设置为评估模式\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "        src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "#     print('src_tokens',src_tokens.shape)\n",
    "    # 添加批量轴\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    print('enc_X',enc_X.shape)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    # 添加批量轴\n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    print('dec_X_shape',dec_X.shape)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        print('y_shape',Y.shape)\n",
    "        print(Y)\n",
    "        # 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入\n",
    "        dec_X = Y.argmax(dim=2) # 返回的不是值，而是索引\n",
    "        print('dec_X_shape',dec_X.shape)\n",
    "        print('dec_X',dec_X)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        print('pred',pred)\n",
    "        # 保存注意力权重（稍后讨论）\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # 一旦序列结束词元被预测，输出序列的生成就完成了\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "667075f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(pred_seq, label_seq, k):  #@save\n",
    "    \"\"\"计算BLEU\"\"\"\n",
    "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "    for n in range(1, k + 1):\n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        for i in range(len_label - n + 1):\n",
    "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
    "        for i in range(len_pred - n + 1):\n",
    "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92c08e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_X torch.Size([1, 10])\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[  8.7597,  -2.8911,  -3.9931,   3.7904,  -2.2284,  -2.4336,  10.0277,\n",
      "            6.4010,  -1.5584,  -4.9922,   0.8506,  -3.7743,   5.8072,  -4.4134,\n",
      "          -13.0039,   4.4440,  13.2510,   6.0377,  -3.1945,  -3.8628,  -4.6365,\n",
      "           -2.5703,   1.1432,  -4.9456,  -9.4841,  -1.5844,   0.6833,   0.5715,\n",
      "          -15.8409,   1.6948, -12.0033,  -1.4407,   0.7959,  -0.9793,  -1.2843,\n",
      "           -4.2051,   3.9267,  -1.8807,   6.8382,  -2.6896,  -1.1599,  -4.3154,\n",
      "           -6.3320,  -2.0866,   4.9179,   2.9755,  -0.0260,  -7.4392,  -0.3778,\n",
      "            3.3004,  -2.6325,   0.5568,  -4.9789,  -1.3490,  -2.9557,  -2.1753,\n",
      "            0.3784,  -1.7779,  -0.1690,   5.5301,  -1.6290,  -2.3908,   1.1536,\n",
      "            2.6644,   3.8860,  -0.2581,  -0.0769,   9.3977,  -2.1353,  -0.0770,\n",
      "            5.0591,   6.4112,  -2.5964,   6.5567,  -0.8403,  -4.3981,  -4.8952,\n",
      "            2.8443,  -0.7940,  -4.1025,  -0.9146,  -0.4057,  -0.7512,   2.3013,\n",
      "           -0.4580,  -3.9434,  -0.2223,  -4.1084,  -8.5168,   2.5047,  -6.4291,\n",
      "            2.0347,   2.0784,   1.4079,  -0.1676,  -0.4359,   9.7732,   2.4005,\n",
      "            3.2264,   4.9853,  -6.3441,  -3.7993,  -0.4927,  -2.7760,   0.2115,\n",
      "           -5.6630,  -0.3883,  -1.8480,   1.3588,  -4.2398,  -3.1659,  -1.1180,\n",
      "           -4.6764,   3.3206,   3.3054,   2.4364,  -0.7472,  -0.0966,   1.6819,\n",
      "            1.4398,   3.8192,  -0.2771,   6.0804,  -3.1548,   2.5021,  -7.0196,\n",
      "            3.6090,   3.1383,  -0.4539,  -6.1870,  -7.2663,   6.1630,  -5.3708,\n",
      "           -6.5176,  -4.8432,  -5.3527,  -4.3231,   0.9016,  -8.8892,  -1.3240,\n",
      "           -0.2643,  -2.2733,  -0.4755,  -4.8625,  -5.2906,  -5.5291,  -5.7921,\n",
      "           -5.0108,   0.1109,   0.2401,  -1.6539,  -3.2876,  -0.7561,   1.7895,\n",
      "            4.2606,   5.1731,  -0.7937,  -5.5234,  -1.2578,  -0.2866,   3.0591,\n",
      "           -3.2436,  -5.3778,  -2.4018,  -1.9498,  -2.3897,  -0.8924,  -5.2933,\n",
      "           -0.3197,   5.7660,  -6.3774,   1.8684,  -2.8193,  -3.2758,  -0.7831,\n",
      "           -0.0383,  -5.0191,  -0.4138,  -5.0918,  -8.9103,  -5.8931,  -1.0960,\n",
      "           -4.4844,  -0.9683,  -3.5086,  -3.6475,   8.3749,  -5.8084,  -2.3489,\n",
      "           -2.2923,  -3.7307,   4.5963,   4.3296,  -0.9925,  -2.1780,  -4.1424,\n",
      "           -2.2676,  -6.2193,  -4.5637,   2.4338,   4.7139]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[16]])\n",
      "pred 16\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[  2.1768,  -2.5149,  -3.6132,   1.9738,   2.2031,  10.8977,  -0.7747,\n",
      "            4.6934,   0.3180,  -1.5934,  -7.6650,  -0.6370,   2.5089,  -5.7989,\n",
      "           -4.7664,   1.3437,   2.8112,   3.6511,  -9.3185,  -0.7376, -10.2549,\n",
      "           -8.3010,   4.8773,   1.4877,  -5.8654,  -0.5876,  -9.1855,   1.5746,\n",
      "           -2.0962,   8.5996, -13.0121,   2.3662,   4.4790,   2.9263,  -5.9952,\n",
      "           -7.7634,   9.5331,   2.1086,   1.4453,  -2.6971,   0.2080,  -8.3911,\n",
      "            1.2094,  -2.8179,   5.9385,   3.2880,  -0.0975,  -2.2116,   2.3943,\n",
      "           -2.9910,  -0.6282,  -4.0485,  -7.7998,   2.6423,  -1.3075,   5.8667,\n",
      "           -5.7705,   0.1604,  -0.2382,  -1.5648,   0.2793,  -2.4309,   0.5417,\n",
      "           -3.1029,  -2.6654,  -3.3439,  -1.1169,  -0.1987,   2.1197,  -2.3122,\n",
      "           -0.6315,  -5.0294,   6.1317,   0.3929,  -1.6597,  -7.9579,  -8.2509,\n",
      "            0.3187,  -2.6354, -11.3357,  -1.8982,  -1.8167,   5.4833,  -3.1045,\n",
      "            4.8955,  -0.4440,   5.4098,  -8.3823,  -2.6670,  -2.2443,  -3.2270,\n",
      "           -2.7680,  -2.2988,  -2.2974,  -6.2145,  -6.5469,  -0.2496,  -3.6845,\n",
      "            3.0295,   1.8945,   5.0941,  -5.5667,  -2.1458,  -4.0322,   3.6502,\n",
      "            1.6696,   1.1995,  -0.3510,   2.5111,  -4.3619,  -2.6914,  -3.5326,\n",
      "           -1.5662,   0.3328,   0.5776,   1.1976,   3.8764,  -1.8540,   0.1510,\n",
      "           -2.9764,  -3.5480,  -4.2685,  -1.7297,   6.1625,   2.9082,   0.0820,\n",
      "           -2.7227,  -3.1518,   1.7378,  -2.3281,  -0.2627,   3.8583,  -4.8563,\n",
      "           -1.0135,  -4.7095,  -3.2590,  -0.6445,   3.7514,  -4.1726,  -4.8892,\n",
      "           -0.1547,   4.2107,  -3.6407,   2.5112,   2.3455,   1.8905,   1.7937,\n",
      "           -2.0305,  -6.1313,  -6.1880,  -0.2719,  -1.2808,  -1.3026,  -3.8741,\n",
      "           -0.5202,   2.6527,   1.4373,   2.3574,  -1.1285,  -2.1004,   2.6231,\n",
      "           -2.0765,   1.8302,   1.0160,   0.7960,   0.4099,   0.3988,  -0.6922,\n",
      "            4.6958,   2.9808,  -2.2289,  -0.2342,   0.5325,  -0.0700,   0.3141,\n",
      "           -3.1836,   0.5435,  -3.3791,   0.7107,  -3.2066,  -2.6693,   0.9501,\n",
      "           -1.8741,  -2.5959,  -1.6534,  -3.7542,  -0.2520,  -2.7530,   2.6460,\n",
      "            3.1014,   2.7121,  -5.3181,  -5.1084,   2.9368,   2.8525,  -6.3459,\n",
      "            2.7433,  -2.9853,  -0.6530,   0.9847,   5.7506]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[5]])\n",
      "pred 5\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[ -1.8442,  -1.1927,  -1.6850,  18.4719,   8.9662,   1.9656,  -0.9244,\n",
      "           -4.8332,  -1.0076,   4.4928,  -1.8884,  -4.5700,  -0.4754,  -8.6457,\n",
      "            1.0196,   1.5450,   0.0481,   1.6668,  -7.2959,  -3.4959,  -2.0934,\n",
      "           -6.2666,   3.4103,  -6.8602,  -4.0984,   3.6435,  -1.6028, -10.6349,\n",
      "            3.1293,   3.7458,  -7.1070,  -5.1990,   7.3052,  -4.6551,  -3.5804,\n",
      "           -1.5164,  -1.3741,   1.8548,   0.3756,  -7.2181,  -5.3331,  -2.3662,\n",
      "           -5.3217,  -1.7428,  -1.5799,   1.2741,  -4.8588,   3.3205,   5.1648,\n",
      "            0.3125,  -3.7421,   5.2792,  -8.1185,  -0.5821,   4.6417,   2.4091,\n",
      "           -0.3365,  -5.9380,   0.2938,  -1.9240,  -0.3129,  -5.8880,   1.5702,\n",
      "           -0.2978,  -0.8543,   0.6076,  -4.7660,   1.8247,   1.7507,  -4.5298,\n",
      "            2.1473,  -1.3348,  -1.9044,  -1.4691,   4.4078,  -3.9673,  -4.2632,\n",
      "           -8.4430,  -2.1647,  -0.6839,  -1.3880,  -1.8386,   2.4334,  -9.7425,\n",
      "           -4.9253,  -0.2845,   1.3142,   2.7051,  -1.6802,  -0.4648,  -4.2334,\n",
      "           -6.2020,  -6.3621,  -4.1966,  -5.7014,  -6.7596,   0.6208,  -2.6727,\n",
      "            4.1724,   1.3739,  -1.5780,  -2.5503,  -2.3734,   1.8267,  -3.8653,\n",
      "            0.5344,  -1.6686,   1.2708,   1.1608,   0.1514,  -3.2198,  -5.7410,\n",
      "           -3.3590,  -3.8447,  -0.1310,  -3.3853,   3.7239,  -1.4361,   1.6977,\n",
      "            0.1689,  -0.8284,  -1.4202,  -1.0625,  -5.4740,   2.5237,   4.8423,\n",
      "            0.6938,   1.4610,   2.3770,  -1.7729,  -2.8792,  -2.1519,  -6.8925,\n",
      "            0.8262,  -2.6630,  -2.8844,   1.0792,   0.8486,  -2.2215,  -2.0791,\n",
      "           -1.2593,   0.0577,  -1.6162,   2.6514,   3.0959,   2.9135,   3.0863,\n",
      "           -2.8630,  -0.2629,  -1.0725,  -0.2091, -11.8979,  -0.4553,  -1.1874,\n",
      "           -1.5013,  -1.9615,  -5.0815,   5.8261,   0.4867,  -4.9249,  -5.1183,\n",
      "            2.8764,  -7.6960,   0.2864,   0.4664,   0.2369,  -1.1599,  -0.9715,\n",
      "            1.5525,   5.3511,  -0.7688,  -0.1755,  -3.1651,  -3.3780,  -1.2972,\n",
      "           -1.7491,   2.5733,  -1.2179,   2.0648,  -4.7762,  -2.7883,   2.9793,\n",
      "           -3.5560,  -0.7932,  -6.7565,   5.0281,   7.4149,  -1.2600,   0.5561,\n",
      "            4.3378,  -1.5427,  -2.8314,  -2.4736,   2.6964,   4.9573,   1.3208,\n",
      "           -4.8213,  -4.8870,  -4.7827,   3.7424,   4.3298]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[3]])\n",
      "pred 3\n",
      "go . => va !, bleu 1.000\n",
      "enc_X torch.Size([1, 10])\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[ 8.4470e+00, -2.8857e+00, -2.6516e+00, -7.2576e+00,  8.8042e-01,\n",
      "          -7.7877e+00,  8.6452e+00,  6.6671e-02, -1.7533e+00, -7.1769e+00,\n",
      "           1.2266e+01,  3.6328e+00, -2.4006e+00,  8.1615e+00, -4.1138e+00,\n",
      "           2.0259e+00,  2.8559e+00, -2.7925e+00,  2.9559e+00,  6.5135e+00,\n",
      "           8.7971e+00,  8.9252e+00, -2.5224e+00,  7.6166e-01, -3.0584e-01,\n",
      "          -4.3959e+00,  8.5578e+00,  6.9172e+00, -6.5106e+00, -4.1276e+00,\n",
      "           7.9229e+00, -2.9580e+00, -5.0543e+00, -7.5994e-01,  1.1868e+00,\n",
      "           3.5248e-01, -8.0479e-02,  8.3176e-01,  2.9683e-01,  6.7764e+00,\n",
      "           3.1617e+00,  1.3363e-01,  6.5426e+00,  5.8355e+00,  2.7759e+00,\n",
      "          -5.4392e+00,  4.5522e+00, -2.8707e+00,  1.8698e+00,  7.7032e-01,\n",
      "          -9.6265e+00,  9.2679e-01,  2.1189e+00,  3.4164e+00, -9.3004e+00,\n",
      "           1.9301e+00,  2.5646e+00, -2.8539e-02,  1.8635e+00, -3.5255e+00,\n",
      "          -8.9138e-01,  6.7299e+00, -1.7732e+00, -2.6974e+00,  2.9405e-01,\n",
      "          -6.3246e+00,  4.2885e+00,  2.9462e+00, -7.2186e+00,  5.4403e+00,\n",
      "          -2.7896e+00,  7.0881e-01, -4.5202e+00, -4.6235e+00, -2.2872e+00,\n",
      "           2.1642e+00,  2.6088e+00,  5.0373e+00, -3.8903e+00,  3.4155e+00,\n",
      "           3.7611e+00,  3.7742e+00, -1.5765e+00,  3.7148e+00,  7.7846e-02,\n",
      "          -2.0426e+00, -4.1223e+00, -7.9403e-01, -1.1514e+00, -8.4086e-01,\n",
      "          -8.8864e-01,  2.0070e+00,  1.8893e+00,  3.4975e+00,  1.7957e+00,\n",
      "           1.7197e+00,  2.9590e+00,  1.4108e+00, -7.7558e+00, -4.0269e+00,\n",
      "          -1.0185e+01, -3.3415e+00,  3.3270e+00, -5.1433e+00, -4.8016e+00,\n",
      "          -1.0290e+01, -5.0118e+00, -6.7574e+00, -3.5294e+00,  5.4125e+00,\n",
      "           2.2852e+00,  5.7281e+00, -2.0586e+00,  6.6105e+00, -1.3644e+00,\n",
      "          -1.5872e+00,  4.6158e-01,  1.9211e+00,  5.0105e-01, -4.8664e+00,\n",
      "          -2.2741e+00, -2.7874e+00,  1.0228e+00,  1.6750e+00, -9.3637e+00,\n",
      "          -3.2267e+00, -3.0254e+00, -2.9046e+00, -4.6878e+00, -6.1166e+00,\n",
      "           8.0106e-01, -6.5872e-01,  2.8563e+00, -1.3875e+00, -8.3239e-03,\n",
      "           3.5601e-01, -1.9814e+00,  3.1215e+00,  4.1358e+00,  4.9260e-01,\n",
      "          -9.0680e-01, -1.9750e+00, -3.5654e+00, -4.1454e+00, -4.7673e+00,\n",
      "          -4.0313e+00, -4.2163e+00,  4.8657e+00,  1.3421e+00,  1.5905e+00,\n",
      "          -1.1464e+00,  7.0148e-01, -5.5091e+00, -2.2238e+00,  2.5420e-01,\n",
      "           2.1227e+00,  5.8012e-02, -2.3030e+00,  3.9033e+00,  3.5217e+00,\n",
      "          -3.2907e+00,  2.9846e+00,  2.4561e+00, -1.8414e+00, -1.4276e+00,\n",
      "          -1.9128e+00, -3.4906e+00, -2.5652e+00, -3.1921e+00, -5.9780e+00,\n",
      "           9.0009e-01, -5.6578e-01, -1.1981e+00, -8.5666e-01, -5.5166e+00,\n",
      "          -9.4835e-01, -2.4979e+00, -1.0848e+00, -2.2270e+00, -2.0538e+00,\n",
      "          -6.4864e+00,  1.1739e+00, -2.3694e+00,  2.1933e-01, -1.6721e+00,\n",
      "          -6.6583e+00, -4.7950e+00, -1.4024e+00, -7.3277e+00, -1.1380e+01,\n",
      "          -5.8955e+00,  2.1860e+00,  2.1100e+00, -1.2871e+00, -4.1311e+00,\n",
      "           9.9187e-01, -1.7103e+00, -2.7203e+00,  1.4772e+00,  7.7080e-01,\n",
      "          -4.1455e+00]]], grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[10]])\n",
      "pred 10\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[  4.8863,  -1.9524,  -1.9042,  -1.7572,  -1.7475,  -5.0694,   7.1645,\n",
      "            0.7990,  -2.1839,  -6.0913,   3.0182,   4.2870,   3.4705,   0.7479,\n",
      "           -3.8915,   5.2674,   1.8036,   3.3028,  -6.8931,  -1.1387,  -1.9301,\n",
      "            5.8792,   4.0590,   8.0771,  -1.0435,   2.9195,  -4.0469,  -1.4805,\n",
      "          -10.1933,   5.8032,  -3.5312,   0.7069,  -7.8438,  -8.8614,  -3.7557,\n",
      "           -3.5476,   9.4096,   5.5442,   2.4043,   4.6460,  -0.8456,  -4.1299,\n",
      "            4.9993,   1.2337,   7.0444,   1.0616,   0.7057,   3.1039,  14.0167,\n",
      "           -3.6703,   0.8394,   6.1734,  -0.2771,   2.4801,  -4.0851,   4.2488,\n",
      "            4.3147,  -0.9478,  -1.1962,  -2.1002,  -7.4858,   4.2508,   4.4051,\n",
      "            1.3472,  -0.8848,  -8.3804,   2.7396,   2.8960,  -6.1486,   6.1862,\n",
      "           -3.6629,  -0.3678,   1.7745,   0.6163,  -3.1786,  -1.1684,  -0.8734,\n",
      "            3.8119,  -4.0901,  -4.3614,  -0.5416,  -0.0857,   2.5735,   0.4735,\n",
      "           -1.3283,  -4.2275,  -3.2925,   0.7567,  -5.6097,  -2.7682,   5.2114,\n",
      "           -2.1947,  -2.1103,   1.3191,  -1.5463,  -1.8533,   5.0145,   3.3824,\n",
      "           -2.9303,  -1.6318,  -6.0944,   1.8835,   6.2077,  -6.1812,   2.6618,\n",
      "           -5.6575,  -4.2303,  -5.2164,  -2.7503,   6.5355,  -0.8551,   2.6566,\n",
      "           -2.2575,   5.3317,  -0.8400,  -0.1235,  -2.5157,   4.6685,   0.2881,\n",
      "           -5.2247,  -3.2316,  -8.1998,  -7.0677,   4.6168,  -0.7207,  -9.7053,\n",
      "           -1.8905,  -1.4693,   1.7172,  -6.0974,   1.4095,   0.2140,  -4.5671,\n",
      "           -5.6550,  -2.9112,  -1.9219,  -3.1702,  -0.9324,  -2.0861,   0.7111,\n",
      "           -1.4466,   2.5294,  -3.2417,  -2.3631,  -2.9471,  -2.2721,  -3.0117,\n",
      "            3.7446,  -3.8953,  -3.7946,   2.6531,   2.7435,  -5.0225,  -5.8344,\n",
      "            2.7233,   3.8685,  -1.5086,   5.3730,  -3.2037,   7.9826,   2.3114,\n",
      "           -0.9374,   2.2409,  -2.3504,  -2.4796,  -2.4059,  -5.4292,  -6.9637,\n",
      "           -2.6036,  -8.4853,  -4.5463,  -2.5225,   3.8922,   4.5214,  -4.1621,\n",
      "           -2.1122,   2.2113,  -2.4868,   1.9215,  -0.6893,  -2.4719,   3.4935,\n",
      "            2.9299,  -1.1201,  -2.0082,  -4.1852,  -3.4579,  -1.6771,  -8.0285,\n",
      "           -6.5333,  -2.1176,   0.0222,   0.2994,   0.9383,   0.5261,  -3.8947,\n",
      "            2.0151,   0.1390,   1.2722,   4.5210,  -1.0802]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[48]])\n",
      "pred 48\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[  5.1854,  -4.1977,  -4.9239,   5.2448,  16.4401,   4.4233,   5.2150,\n",
      "            1.7038,   4.4986,  -2.4129,   1.5399,   3.9682,  -1.1512,   2.3581,\n",
      "           -4.6099,   6.2302,  -0.3498,  -3.9591,  -4.9376,   5.6456,  -2.7299,\n",
      "            1.6134,   3.7635,   7.0034,  -0.6217,  -1.3915,  -2.0990,  -5.8464,\n",
      "           -2.4483,   2.4864,  -5.8869,  -2.0202,  -2.3158,  -3.7739,  -1.9157,\n",
      "          -10.9951,  -1.5868,   1.0206,  -5.9592,  -1.4758,  -5.1334, -10.9300,\n",
      "            1.2555,  -1.3667,   5.1089,  -2.9936,  -0.1622,   7.1244,   9.6227,\n",
      "           -7.6613,  -1.2470,   2.2579,  -3.8982,   3.0861,  -8.0842,   4.3689,\n",
      "           -0.5660,  -6.3387,  -1.2042,  -5.2848,   0.6585,  -1.5683,   2.1943,\n",
      "           -2.6779,  -4.3950,  -7.6987,  -5.8342,  -2.6355,  -2.0844,  -0.8904,\n",
      "           -5.5678,  -4.1427,   0.2686,  -4.3708,  -0.5169,  -4.9200,  -4.9338,\n",
      "           -2.2730,  -3.3755,  -2.3353,  -0.8523,  -1.5767,  -0.8456,  -9.2541,\n",
      "           -5.9829,  -0.6313,  -2.9567,   1.0557,  -4.4980,  -6.7707,  -4.0484,\n",
      "           -7.3756,  -7.7312,  -6.7648,  -3.8463,  -4.5246,  -1.0142,   1.8405,\n",
      "            4.1815,  -0.8441,  -4.0086,  -6.3827,   1.0869,  -2.4346,  -7.0559,\n",
      "           -3.3006,  -6.6407,  -2.9396,  -2.6073,  -1.8385,   0.1292,  -6.9210,\n",
      "           -4.7943,  -0.2096,  -1.0786,  -5.2242,  -1.9125,  -1.3824,  -2.9307,\n",
      "           -4.4925,  -6.0651,  -4.2244,  -3.1855,  -0.7077,  -1.7588,   0.8036,\n",
      "           -5.7187,  -5.4487,   2.1474,  -4.9185,  -7.9581,  -2.9069,  -5.7699,\n",
      "            1.2817,   2.3596,  -3.6636,   0.8847,   4.9489,   2.4953,  -0.3639,\n",
      "           -2.5909,   1.1263,  -3.2462,   2.2693,   2.3562,   2.9036,   2.2340,\n",
      "           -2.0839,  -3.0596,  -3.0698,  -2.2944,  -5.0063,   4.7330,  -6.3923,\n",
      "           -1.2992,   1.5720,  -5.2498,   4.7118,   3.0861,  -7.6566,  -3.0265,\n",
      "            1.3047,  -2.8188,  -0.4119,  -0.4956,   0.1273,  -1.8566,  -7.1917,\n",
      "           -0.3561,   0.5222,   1.7839,  -0.3842,  -1.9348,  -2.0671,  -5.4730,\n",
      "           -4.1762,  -5.2406,  -4.3224,  -5.6615,  -7.7784,  -6.9554,   5.1845,\n",
      "           -0.9323,  -5.0242, -11.0770,  -7.4743,  -3.0962,  -9.6577, -10.1382,\n",
      "           -3.1427,  -1.9642,   0.1773,   0.1929,  -1.7680,  -6.8237,  -2.3336,\n",
      "           -2.5855,  -6.7622,  -3.5715,   0.4835,  -2.4025]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[4]])\n",
      "pred 4\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[  0.7723,  -1.4473,  -1.8756,  19.2805,  10.5894,   2.4528,  -1.9866,\n",
      "           -5.4823,  -3.9747,   4.7538,  -0.8634,  -3.4330,  -1.6088,  -7.9527,\n",
      "           -1.1279,   4.1764,   2.7524,  -1.0362,  -7.1740,  -4.4017,  -2.4860,\n",
      "           -4.3265,   3.5139,  -8.2592,  -4.5039,   5.0390,  -0.9898, -10.9290,\n",
      "            1.9485,   5.1369, -11.3407,  -4.5755,   5.9962,  -4.7381,  -4.6001,\n",
      "           -3.1482,  -3.2109,   0.5619,  -2.5070,  -4.9617,  -6.9926,  -3.9071,\n",
      "           -6.9925,  -2.1632,  -3.1937,  -0.9587,  -5.5830,   4.7506,   5.8162,\n",
      "            0.1350,  -5.2639,   6.4741,  -6.0661,  -0.8663,   7.8713,   2.5879,\n",
      "            1.5677,  -4.9695,   0.2150,  -2.4469,  -0.2658,  -3.7598,   4.1730,\n",
      "           -1.4825,   1.1836,  -2.1768,  -1.6523,   2.4583,  -0.0981,  -6.6765,\n",
      "            1.4361,  -0.7029,  -1.2238,  -0.7646,   2.1361,  -6.7138,  -6.4533,\n",
      "           -7.8937,  -1.6378,  -2.8707,  -5.0559,  -4.9789,   2.1249,  -8.0866,\n",
      "           -6.9741,   0.3837,   0.9595,   0.2711,   0.5640,   0.3847,  -5.0338,\n",
      "           -7.5240,  -7.8533,  -1.0830,  -4.9078,  -5.7396,   1.5209,  -0.5695,\n",
      "            5.8170,   3.8065,  -3.6984,   0.1047,   0.6944,  -1.0312,  -3.1068,\n",
      "           -3.4240,  -1.6285,  -2.4378,   0.0493,  -1.6236,  -5.0481,  -7.8404,\n",
      "           -3.4839,  -4.2984,   0.2906,  -3.3979,   3.2226,  -4.2414,   0.3201,\n",
      "            0.4147,  -0.5201,   0.3123,   1.1637,  -6.8963,   3.0193,   1.8265,\n",
      "           -5.0092,  -4.3450,  -0.7826,  -1.9193,  -1.5181,  -1.3812,  -7.2757,\n",
      "           -1.9722,  -3.5089,  -4.2956,  -1.2554,  -0.1425,  -0.4791,  -2.0739,\n",
      "            1.6779,  -0.1367,  -1.2656,   3.0547,   3.5039,   2.9823,   3.3930,\n",
      "           -5.5766,  -0.5567,  -1.4628,  -0.3438, -13.0005,   1.0417,   2.3814,\n",
      "            1.1302,  -1.1368,  -7.8247,   1.7791,   1.0357,  -1.8448,  -3.4039,\n",
      "            2.0099,  -5.9732,   1.6603,   1.6120,   1.9392,  -3.1646,  -1.0343,\n",
      "            0.5869,   5.3593,  -0.9540,   0.3878,  -3.3276,  -3.5560,  -0.8488,\n",
      "           -1.2831,   2.0378,  -1.2163,   1.8328,  -5.6863,  -6.8679,   1.9445,\n",
      "           -6.6595,  -2.0003,  -7.2586,   3.9539,   4.0544,  -3.6508,  -1.4152,\n",
      "            3.3780,  -3.2535,   0.3331,   0.8894,   2.7692,   4.2664,  -0.6538,\n",
      "           -5.3574,  -9.0770,  -6.2816,   4.6364,   5.0743]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[3]])\n",
      "pred 3\n",
      "i lost . => j'ai perdu ., bleu 1.000\n",
      "enc_X torch.Size([1, 10])\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[  0.7053,  -0.3780,  -1.3165,  -2.6679,  -7.6777,  -9.7481,   7.1815,\n",
      "            0.5718,   2.4166,  -6.3143,   7.3118,   9.8932,  -1.3723,   5.0354,\n",
      "            0.5717,   3.7946,   1.3465,  -2.5373,  16.0165,  -5.3509,   7.7516,\n",
      "           10.6089,   0.8761,  -5.2618,   3.2683,   4.3255,   9.8463,   7.4930,\n",
      "           -5.8561,  -8.1668,   7.0544,  -3.7297,  -5.8467,  -0.2995,   5.2201,\n",
      "            8.3941,  -7.5744,  -3.1595,   2.6569,   2.2898,   3.8774,   8.5635,\n",
      "            3.5187,   2.7716,   0.4532,  -4.2619,   2.2574,  -3.5980,  -2.1425,\n",
      "            4.5534,  -3.2604,   0.7507,   4.9477,  -0.7673,  -0.5850,  -4.7452,\n",
      "            4.4829,   2.7997,  -0.2788,   0.9493,   2.6562,   1.6939,   0.9391,\n",
      "            9.5548,   7.4573,  -3.9237,   2.6605,   1.5268,   0.3006,  -1.2577,\n",
      "            2.6639,   6.1915,  -2.6710,   2.5844,   2.5968,   7.8235,   7.6392,\n",
      "           -1.9963,  -1.8033,   7.5085,   2.2036,   2.4601,  -1.3597,   5.7014,\n",
      "           -7.7418,   0.7510,  -4.5712,   2.8261,  -4.0450,   6.5611,   5.2355,\n",
      "            2.0794,   2.5419,   2.9900,   5.2143,   4.9486,   1.7503,   2.5375,\n",
      "           -8.0876,  -2.1092,  -2.8297,   1.6154,  -2.4232,  -6.0170,  -1.0023,\n",
      "           -6.8010,   1.0359,   1.6243,  -3.3418,   2.5715,  -1.0595,   3.5166,\n",
      "            0.9073,  -1.0391,  -1.3276,   3.2429,  -6.5929,  -0.4265,   1.2462,\n",
      "            1.8276,   2.8869,   0.1834,   0.4551,  -2.1590,   0.4603,  -6.5844,\n",
      "            3.9678,   3.8298,  -1.7743,   3.3670,  -1.4174,  -7.6616,   2.8384,\n",
      "           -3.6363,  -1.6945,  -0.2423,  -3.3249,  -8.1280,   0.2419,   7.1875,\n",
      "            0.0795,  -2.2674,  -0.9679,  -3.7314,  -4.0900,  -4.2206,  -3.3363,\n",
      "            4.5487,   5.0488,   5.0773,   2.7047,   1.1467,   0.2295,   3.2723,\n",
      "            1.2522,  -2.6370,  -1.6201, -11.5515,  -1.6843,   3.8239,   4.3591,\n",
      "           -4.3366,  -3.1565,  -0.7640,  -0.9293,  -0.8463,  -3.8919,  -1.0429,\n",
      "           -6.1983,  -3.6262,  -2.6491,  -0.6724,   3.0245,   3.5697,   0.8254,\n",
      "            9.9861,  -0.7181,  10.1924,  -0.2579,   4.1353,   1.1259,  -3.3916,\n",
      "            0.9565,   6.2559,   3.0725,  -0.4454,   1.7276,  -0.2120,  -3.8982,\n",
      "            1.4006,  -0.5355,   5.4106,   4.8121,  -1.6906,  -1.3848,   2.1950,\n",
      "           -0.0372,   3.0977,  -4.6017,  -1.0235,  -2.6601]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[18]])\n",
      "pred 18\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[  5.8027,  -1.8230,  -1.8494,  -3.2652, -10.3651,  -2.9677,  -8.6537,\n",
      "           -5.1474,  -1.3081,   0.2632,  -4.1375,  -3.2779,  -6.4521,  -0.7741,\n",
      "           12.7118,   1.1762,   0.4728,   0.6477,   1.0538,   0.2563,   0.3359,\n",
      "           -2.7387,   5.2435,   5.2511,  -3.7676,   2.9812,   1.1642,  -1.4771,\n",
      "            4.3919,  -3.4673,   5.6226,  -1.2541,  -1.3661,  -3.6023,   4.7231,\n",
      "            1.1484,   5.0093,   3.9338,  -9.3026,   8.1051,   5.7925,   0.4147,\n",
      "           -4.0067,  10.7770,  -2.1911,   2.2555,   4.5312,  -1.4711,  -1.7327,\n",
      "            4.1404,   2.6229,   0.9822,   4.6624,   3.1751,  -1.1891,  -4.0812,\n",
      "            5.6828,   2.2804,   6.3699,   0.0224,  -0.0270,   5.6658,  -3.8881,\n",
      "           -8.3382,  -2.9987,  -1.2977,   5.6119,   1.1040,  -7.5956,   3.9566,\n",
      "           -7.3927,   1.3875,  -1.3598,  -0.9691,   0.5367,  -2.9066,  -3.1789,\n",
      "           -4.4952,  -0.3384,  -1.1685,  -3.4862,  -3.1191,   3.0135,   2.5400,\n",
      "            1.0581,   1.7868,  -1.5220,  -4.1959,   2.4311,  -3.0706,   2.1102,\n",
      "            2.3455,   3.0521,   3.7272,   2.3898,   2.0445,   0.2861,   2.2366,\n",
      "           -6.0458,  -4.5269,  -1.9039,   4.9642,   3.9332,  -0.5517,   0.9886,\n",
      "           -6.7010,   2.9468,  -0.8998,  -1.9252,   1.4421,   2.6001,   1.7745,\n",
      "           13.8753,   1.9565,  -4.2425,   4.1327,   1.2362,   2.6756,   2.1789,\n",
      "           -5.9878,   1.5260,  -1.0127,  -2.9280,   0.7540,  -4.9475,  -5.9826,\n",
      "           -2.4385,  -2.3216,   5.4423,  -0.3092,  10.1811,  -4.6284,   8.8818,\n",
      "            1.1296,  -2.7987,   8.9588,  10.0803,  -1.9659,   2.6436,  -4.5241,\n",
      "           -0.3470,  -1.7874,  -0.2518,  -1.5153,  -1.7323,  -1.5710,  -1.8233,\n",
      "           -5.4809,  -0.9256,  -1.1079,  -1.5749,   2.7709, -10.0401,   3.6343,\n",
      "           -0.5133,  -4.8345,  -0.1528,  -2.0199,  -1.8810,   3.9132,  -0.8822,\n",
      "            1.1899,  -3.7820,  -0.0877,  -0.6532,   0.7692,  -0.9169,   5.4709,\n",
      "           -0.3191,  -2.7420,   2.2603,  -9.0475,   4.1061,   3.8546,  -4.7240,\n",
      "           -1.7071,   4.1241,  -1.5754,   4.3648,   3.1294,   2.9818,  -2.8350,\n",
      "            6.6410,  -2.4245,   8.3879,   3.4355,  -7.5051,   5.4270,   5.9264,\n",
      "           -5.5336,   1.6214,  -0.0182,   0.2858,   1.7270,   1.5537,  -1.9074,\n",
      "            1.4758,  -1.8162,  -1.2493,  -3.5787,  -2.6259]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[112]])\n",
      "pred 112\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[  4.8482,  -1.5890,  -2.7729,   1.6032,   1.1727,  -6.6131,  -0.4673,\n",
      "           -5.4374,  -3.9388,  -0.0993,   1.6099,   2.2966,  -9.6105,  -0.7072,\n",
      "            6.2510,  -0.3286,  -1.5949,  -4.3033,   3.2916,   0.9639,   2.1628,\n",
      "            1.3761,   1.7606,  -3.2647,   3.6841,   9.0746,   3.2296,   0.5616,\n",
      "            5.6298,  -7.5769,   7.1831,  -2.5149,   5.8629,  -5.2649,   7.6011,\n",
      "            3.1056, -12.5700,   0.1271,  -4.0248,   1.9542,   6.9218,   2.6209,\n",
      "           -1.8146,   2.3615,   1.7885,  -7.8127,   0.1205,   5.2218,   1.5056,\n",
      "           -0.2389,  -3.3675,   1.3527,   0.6751,   1.3789,  -0.8375,   1.5207,\n",
      "           -0.6807,   0.2771,   2.2892,  -1.1420,   8.1304,   0.7592,   2.3715,\n",
      "           -2.9618,   1.4170,  -2.0213,   0.0728,   0.8530,  -1.6543,  -0.3823,\n",
      "           -0.2244,  -1.3891,  -3.9129,   1.0510,   1.5845,   1.3036,   1.6990,\n",
      "           -7.1290,  -4.0454,   6.5414,  -1.3407,  -1.0168,   1.2131,   3.2899,\n",
      "           -5.7414,   4.8004,   1.2086,   1.3451,   0.4554,  -0.2218,  -2.3855,\n",
      "            0.1621,   0.3961,   0.1260,  -1.3952,  -1.6905,  -0.8282,  -2.2993,\n",
      "           -5.2632,  -5.3273,  -3.0589,  -2.8787,  -3.0100,  -5.9953,  -4.5276,\n",
      "           -5.0493,   4.1627,   4.6936,   1.0221,   1.7078,  -4.1459,  -2.7167,\n",
      "            1.3395,  -4.7163,  -2.4486,   3.3272,   2.4734,  -1.0029,   4.2350,\n",
      "           -0.7557,  -0.7517,  -1.0421,  -0.8512,  -4.2086,  -2.7513,  -3.8588,\n",
      "           -2.4003,  -2.5645,  -1.7893,   3.6695,  -0.6763,  -3.1940,  -1.2054,\n",
      "            1.4672,   0.5335,   3.1887,   4.0560,  -4.8711,   7.0840,  -0.9354,\n",
      "           -1.3078,  -1.5500,  -3.5610,   2.3328,   2.1533,   2.3161,   2.7030,\n",
      "           -0.7810,   1.1754,   0.8032,   1.2420,  -2.6794,  -2.2395,   1.1063,\n",
      "            0.7255,  -5.8874,  -4.0360,  -2.1455,   2.7643,   0.5596,  -2.5164,\n",
      "            2.7593,   0.9470,   2.5668,   2.5874,   2.2659,   1.3239,   8.0693,\n",
      "            1.0111,   2.0111,  -1.4561,  -0.8074,  -0.5997,  -0.3188,  -4.1920,\n",
      "            3.2278,   2.2479,   3.4278,   2.0934,   4.2956,   1.3874,  -7.2927,\n",
      "           -3.8223,   3.5790,  -2.7133,   0.4478,  -7.1195,   0.8349,  -1.8088,\n",
      "            1.7454,  -4.1640,  -2.0294,  -2.0104,   2.6262,  -1.6584,   3.5377,\n",
      "           -0.7016,  -1.5179,  -1.6076,   2.6251,  -1.1270]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[25]])\n",
      "pred 25\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[ 1.1698e+00, -1.2077e+00, -1.2943e+00,  1.2108e+01,  7.3004e+00,\n",
      "           6.3941e-01, -7.2818e+00, -8.1564e+00, -6.1811e+00,  5.8137e+00,\n",
      "          -2.1440e+00, -2.9825e+00, -8.7114e+00, -4.0259e+00,  5.0676e+00,\n",
      "          -1.5320e+00, -4.1331e+00, -3.5951e+00, -6.1801e+00,  1.6499e+00,\n",
      "           1.2091e+00, -7.5198e+00,  3.3419e+00, -3.7601e+00, -3.1212e-01,\n",
      "           6.3667e+00,  7.0006e-01, -1.0497e+01,  9.2458e+00,  3.8750e+00,\n",
      "           1.8939e+00, -4.6149e+00,  1.0892e+01, -5.1259e+00, -2.1648e+00,\n",
      "           1.0757e+00, -4.1671e+00,  1.5648e+00, -8.1391e+00, -1.9037e+00,\n",
      "          -1.6620e+00, -2.7736e-02, -6.6426e+00,  1.4560e+00, -3.1856e-01,\n",
      "          -6.6722e-01,  1.0402e+00,  6.7251e+00,  2.9969e+00,  6.8964e-01,\n",
      "          -2.7762e+00,  2.4904e+00, -3.0180e+00, -1.1050e+00,  2.5169e+00,\n",
      "          -3.8576e-01,  1.7366e+00, -3.1976e+00,  2.9676e+00, -2.8882e+00,\n",
      "          -8.5939e-01, -2.1414e+00,  1.8177e+00, -9.4521e+00, -2.9686e+00,\n",
      "          -1.2159e+00,  1.6536e+00, -1.4789e+00,  8.0881e-01, -1.8121e+00,\n",
      "          -2.0854e+00, -1.2663e+00, -3.4378e+00, -2.5755e+00,  2.1944e+00,\n",
      "          -3.8567e+00, -3.5557e+00, -7.9338e+00,  1.4786e+00,  4.0430e-01,\n",
      "          -4.1412e+00, -3.8509e+00,  1.6000e+00, -5.0619e+00, -1.2240e+00,\n",
      "           1.4148e-02,  6.9887e-01,  2.2574e+00,  4.6568e+00, -2.7720e+00,\n",
      "          -2.7139e+00, -5.0684e+00, -5.1413e+00,  6.9142e-01, -4.2867e+00,\n",
      "          -5.0671e+00, -2.2184e+00, -4.2853e+00, -2.6243e-01, -3.5920e+00,\n",
      "          -2.3946e+00,  5.1942e-02,  8.7881e-01,  1.8501e+00, -4.8025e+00,\n",
      "          -1.2423e+00, -1.3245e+00,  1.9215e-01,  2.1092e+00,  1.6214e+00,\n",
      "          -3.3626e+00, -5.1542e+00,  1.6829e+00, -1.2018e-02, -1.1739e+00,\n",
      "          -1.3464e+00,  6.6754e+00, -1.2344e+00,  1.7539e+00, -2.1965e+00,\n",
      "          -1.8727e-01,  9.4650e-01,  1.2933e-01, -3.2782e+00, -1.2415e+00,\n",
      "           6.9274e-02, -5.0117e+00, -4.1742e+00,  1.7229e+00,  1.6214e+00,\n",
      "           1.0792e+00, -1.9609e+00, -6.4200e-01,  4.1934e+00, -5.7780e-01,\n",
      "           1.5288e+00,  3.5358e+00, -1.9572e+00,  2.8030e+00, -5.2667e+00,\n",
      "           2.8038e+00, -4.9204e+00,  1.3189e+00,  6.0001e+00,  6.6206e+00,\n",
      "           6.7906e+00,  6.8871e+00, -2.8627e+00, -1.2356e+00, -1.4734e+00,\n",
      "           1.6584e+00, -1.1074e+01, -3.5338e+00,  2.0337e+00, -2.9696e+00,\n",
      "          -6.5284e+00, -3.8812e+00,  3.3154e+00,  4.5816e-02, -1.9874e+00,\n",
      "          -6.0547e+00,  4.9292e+00, -1.9130e+00, -1.2446e+00, -1.1607e+00,\n",
      "          -6.1758e-01, -3.8564e-01,  3.6840e+00,  1.8684e+00,  2.3764e+00,\n",
      "           2.0847e+00, -3.3846e+00, -2.9196e+00, -3.2805e+00, -5.7718e+00,\n",
      "          -3.3937e+00,  3.7308e+00, -3.4788e+00,  2.8592e+00, -2.1497e+00,\n",
      "          -2.8705e+00, -1.8971e+00, -3.8162e+00,  4.8923e+00,  1.6297e-01,\n",
      "           3.8871e+00, -1.8693e+00,  2.8523e+00,  9.2585e-02,  6.5993e-01,\n",
      "          -7.9234e-01, -2.5797e+00, -1.7655e+00,  2.4596e+00,  1.4223e+00,\n",
      "          -5.6726e-01, -1.8445e+00, -5.4406e+00, -1.6742e+00,  4.8164e+00,\n",
      "           4.0332e+00]]], grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[3]])\n",
      "pred 3\n",
      "he's calm . => il essaye gagné, bleu 0.000\n",
      "enc_X torch.Size([1, 10])\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[  5.9410,  -2.8613,  -4.1463,  -1.3049,   0.1240,  -7.4568,  18.0475,\n",
      "            6.1223,   5.2880, -14.0157,  11.0244,   3.4895,   4.5975,   1.7852,\n",
      "           -8.3232,   6.1465,   6.6352,  -0.9270,   4.1047,   0.8317,   0.6443,\n",
      "            5.2270,  -1.0480,  -2.8290,   0.0408,  -0.7650,   2.6410,   6.0867,\n",
      "          -15.8264,  -2.8663,  -2.6339,  -3.2898,  -5.2989,  -0.9992,  -4.1073,\n",
      "           -1.2824,  -0.6292,   2.1146,  12.2501,  -0.6750,  -3.2215,  -1.0457,\n",
      "            5.3848,  -1.8568,   7.7670,  -3.7221,   0.0638,  -5.6246,   4.6981,\n",
      "           -1.4628,  -4.8064,   2.7973,  -5.3484,  -1.2584,  -6.5285,   2.5756,\n",
      "           -2.3833,   1.2371,   0.0458,  -0.3752,   1.9947,  -0.7284,   0.5796,\n",
      "            7.8166,   3.0219,  -2.3783,  -0.6883,   5.9877,  -6.1629,  -0.6863,\n",
      "            1.8801,   1.2328,   0.2484,   0.9883,  -1.2932,   0.7436,   0.4505,\n",
      "            1.1480,  -6.0047,   2.0906,   4.4121,   4.0556,  -3.8281,   3.0806,\n",
      "           -3.3282,  -1.6768,  -2.7729,  -0.4441,  -8.8517,   1.0974,  -2.2464,\n",
      "            4.2519,   4.2386,  -1.5301,  -3.1525,  -3.3822,   4.6036,   0.6096,\n",
      "           -0.0748,   3.2123,  -6.8179,  -7.4701,  -4.2351,  -8.8433,  -2.6337,\n",
      "           -7.2019,  -7.9736,  -4.2709,  -5.9791,   2.2163,   0.1486,   5.9387,\n",
      "           -6.2070,   3.5522,   2.2429,  -1.5409,  -5.9230,  -1.2984,   2.7980,\n",
      "           -1.4892,  -1.9094,  -3.4091,   1.3287,  -0.4224,  -4.3069,  -3.7765,\n",
      "            5.0764,   5.0050,  -1.4736,  -6.5432,  -5.8276,   2.0924,  -8.9751,\n",
      "           -7.2469,  -3.0899,  -4.7691,  -4.6760,   4.0675,  -3.7464,   4.1231,\n",
      "           -2.8979,   1.2463,  -5.1475,  -6.0407,  -6.7246,  -6.0806,  -6.4879,\n",
      "            6.1441,   3.1374,   3.2338,  -5.7782,   0.7873,  -0.7577,  -4.8961,\n",
      "            4.5036,   4.0594,  -3.0075,  -1.8289,  -0.6985,   3.0581,   2.6036,\n",
      "           -0.6003,  -3.4678,  -0.9187,  -0.5012,  -1.8597,   1.7374,  -5.3716,\n",
      "           -3.5329,  -1.2503,  -3.9966,   7.1684,  -2.4473,  -1.4968,  -3.7635,\n",
      "            2.4437,  -5.6067,   2.6438,  -5.3739,  -7.0154,  -5.7709,   2.3837,\n",
      "           -5.5211,  -0.6752,  -7.0043,  -5.5637,   3.0869,  -7.1645,  -7.2416,\n",
      "           -5.3753,  -3.1896,  -0.3912,  -0.6967,  -3.2368,  -4.3621,   2.6475,\n",
      "           -3.6088,   2.7476,  -2.8420,   0.0739,  -3.9592]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[6]])\n",
      "pred 6\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[  8.3020,  -4.3249,  -5.4857,  -3.8335,  -2.6811,  -0.3296,   5.2589,\n",
      "           15.9960,   7.4246, -15.6852,   2.0037,   1.2669,  -5.9861,   2.9428,\n",
      "           -3.8430,   2.7444,   7.5020,   0.1478,   4.0445,   6.1790,  -1.3108,\n",
      "           -6.1602,  -3.2898,   2.9916,  -1.5309,  -4.9362,  -0.8405,   5.1893,\n",
      "          -12.3888,   2.4160,  -7.9930,  -5.7674,  -2.3288,  10.0304,  -6.5918,\n",
      "           -6.6350,   4.4627,   1.2529,   2.7381,  -2.5998,  -1.8137,  -6.7388,\n",
      "            6.3676,   0.2604,   3.1897,  -3.8469,   7.8039,  -9.4526,  -1.0678,\n",
      "           -0.0794,   1.7327,  -2.9592,  -5.0176,  -1.5903,  -7.4627,  -0.3241,\n",
      "           -7.3322,   8.5361,   6.3276,  -2.4785,   3.2514,  -2.6593,  -0.5730,\n",
      "           -0.1633,  -4.4241,  -1.3733,   2.1100,   0.3933,  -3.9760,   0.1394,\n",
      "            0.1438,  -4.5077,   1.4012,  -1.7400,  -1.5970,  -5.5852,  -5.3824,\n",
      "            0.6869,  -6.2214,  -3.2808,   3.1067,   2.8956,  -3.1267,  -1.2466,\n",
      "            2.8623,  -1.6987,  -1.9780,  -5.3173,  -8.7531,  -6.3529,  -4.4061,\n",
      "            4.3271,   4.1317,   1.3373,  -3.1801,  -3.5185,   0.1543,  -2.6074,\n",
      "            1.0842,   3.7520,   3.3364,  -7.1255,  -5.9052,  -9.5928,   1.2307,\n",
      "           -8.6512,  -6.9861,  -1.2477,  -4.5808,  -1.7795,   1.4541,   0.4590,\n",
      "           -0.9212,   5.8448,  -3.9715,  -3.2883,   0.5921,  -3.8047,   2.4709,\n",
      "           -1.6999,  -5.9718,   0.3029,   4.7905,   5.2547,  -5.1542,  -3.2229,\n",
      "            0.3846,  -0.3449,   0.9639,  -5.5348,   1.3398,   1.3289,  -4.1050,\n",
      "           -5.2799,  -1.8822,  -2.0862,  -1.4546,   8.7542,  -0.5900,  -3.3202,\n",
      "           -2.3478,  -2.8159,  -5.3270,  -3.6262,  -4.0136,  -3.6078,  -3.9542,\n",
      "            0.2484,  -0.4247,  -0.0425,  -4.5743,  -0.8999,   1.7343,  -4.4495,\n",
      "           -0.3468,   0.9703,  -1.2045,  -0.6214,   3.4873,  -0.6837,   2.8885,\n",
      "            2.9637,  -2.9278,   0.3634,   0.5268,   0.0362,   7.4488,   0.1456,\n",
      "           -3.1379,  -0.7750,   1.1530,   4.3525,  -0.2775,   0.1709,  -5.0277,\n",
      "           -2.0346,  -5.1871,  -2.5831,  -4.7877,  -4.4633,  -5.1058,   3.7183,\n",
      "           -1.8080,  -6.2315,  -2.4934,  -6.1397,  -4.4407,  -9.6401,  -1.5865,\n",
      "           -2.7421,   2.5597,  -3.2966,  -4.0727,  -3.1678,  -6.8923,  -0.2035,\n",
      "            1.3148,  -3.9689,   1.6992,  -4.4379,  -0.3784]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[7]])\n",
      "pred 7\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[ 6.4418e+00, -3.0246e+00, -3.6916e+00, -4.1134e+00, -9.1274e+00,\n",
      "          -2.4780e+00, -1.1912e-01,  9.9487e-01,  2.7552e-01, -1.1748e+01,\n",
      "           7.5515e-01, -6.8058e+00, -5.5208e+00,  2.4799e+00,  1.3161e-01,\n",
      "           1.4303e+00,  6.2501e+00,  1.5797e+00, -1.5632e+00,  5.3917e+00,\n",
      "          -8.9470e-01, -5.6144e+00,  3.9437e+00,  3.3619e+00, -7.1707e-01,\n",
      "          -4.6807e+00, -6.9234e-01, -5.7563e-02, -4.6284e+00, -1.1890e-01,\n",
      "          -2.1169e+00, -6.4393e+00,  1.6599e+00,  2.4664e+00,  5.1534e-01,\n",
      "          -2.4147e+00,  6.9573e+00,  1.0297e+01,  1.6271e+00,  9.0823e-01,\n",
      "          -3.7835e-01, -2.0460e+00,  4.7554e+00,  3.8907e+00,  2.5032e+00,\n",
      "           8.0057e-01,  6.7511e+00, -7.2074e+00, -1.7589e+00,  4.3317e+00,\n",
      "           4.1828e+00, -1.0167e+00,  1.5649e+00,  2.1875e+00, -6.0939e+00,\n",
      "          -1.6987e+00, -1.5794e+00,  7.6591e+00,  8.6145e+00, -3.8586e-01,\n",
      "          -4.9184e-01,  9.8312e-01, -5.2040e+00, -5.5123e+00, -4.0891e+00,\n",
      "          -5.7476e-01,  5.1575e+00,  3.0049e+00, -8.3817e+00,  5.6914e+00,\n",
      "           2.1094e+00, -2.3095e+00, -3.2073e+00, -7.6440e-01, -2.1113e+00,\n",
      "          -3.7708e+00, -3.6902e+00, -3.7698e+00, -1.7265e+00, -1.3552e+00,\n",
      "           3.0201e+00,  3.1757e+00,  1.7976e+00, -1.1659e-01,  2.3438e+00,\n",
      "          -3.9835e+00, -3.7947e+00, -4.0570e+00, -4.0449e+00, -6.0146e+00,\n",
      "           1.3424e+00,  4.4846e+00,  4.1728e+00,  5.2474e+00, -2.1945e+00,\n",
      "          -2.4718e+00,  3.2437e+00, -2.6115e+00, -2.5858e+00, -2.4783e+00,\n",
      "           4.7541e+00, -5.5877e-01,  1.0069e+00, -3.7407e+00, -1.5994e+00,\n",
      "          -8.3685e+00, -5.2322e+00, -3.8123e+00, -2.8909e+00, -3.9559e+00,\n",
      "           4.6123e+00,  5.2385e+00,  5.4349e+00,  1.2431e+00, -3.3459e+00,\n",
      "          -3.6983e+00,  2.6768e+00,  2.9083e-02,  4.5312e+00,  1.0671e-01,\n",
      "          -3.6475e+00, -3.6177e+00, -1.7328e-02,  2.1907e+00, -8.3853e+00,\n",
      "          -4.1527e+00,  1.1601e+00,  5.1634e-01,  6.1188e+00, -3.1433e+00,\n",
      "           5.9405e+00,  7.5695e-01,  5.7788e+00, -3.2313e+00, -2.8648e+00,\n",
      "           5.5795e+00,  6.5497e+00,  3.8847e+00, -1.8750e+00, -6.6475e+00,\n",
      "          -5.7614e+00, -3.1109e+00, -1.1965e+00, -2.3902e+00, -2.5082e+00,\n",
      "          -2.0362e+00, -3.1324e+00, -1.9161e+00, -2.2685e+00, -2.1293e+00,\n",
      "          -4.0146e+00,  9.0319e-03, -5.8376e+00, -5.7112e+00, -6.2718e+00,\n",
      "          -4.0356e+00, -2.7538e+00,  3.9259e+00, -7.8299e-02,  3.7050e+00,\n",
      "          -1.2588e+00,  8.4603e+00, -4.6645e+00, -1.6797e+00, -1.6542e+00,\n",
      "          -1.9295e+00,  4.8207e+00,  5.4638e+00, -4.7103e+00, -3.0043e+00,\n",
      "          -3.2216e-01,  1.9701e+00,  2.1069e+00,  2.0265e+00, -5.8934e+00,\n",
      "          -3.6884e+00,  2.9618e-01, -4.3408e+00,  3.6165e-01, -2.2765e+00,\n",
      "          -5.2165e+00,  2.2003e-01,  5.9289e+00, -5.3969e+00,  3.2848e+00,\n",
      "           1.8194e+00, -6.6021e+00, -7.9515e-01,  2.3695e+00, -5.4602e+00,\n",
      "          -6.4951e-01, -2.4541e+00, -3.0404e+00,  1.4241e+00, -1.5149e+00,\n",
      "           5.9963e+00,  3.3976e+00, -1.1212e+00,  3.3060e+00, -3.8477e+00,\n",
      "          -1.1908e-01]]], grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[37]])\n",
      "pred 37\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[  4.5986,  -1.5852,  -1.6869,  -4.6179, -12.6103,  -7.4239,   2.3233,\n",
      "           -1.5574,  -0.2312,  -9.5659,   2.3157,  -1.9440,  -4.1240,   1.9951,\n",
      "           -1.5670,  -1.3537,   1.3812,   5.1930,   4.0310,   3.8685,  -0.5302,\n",
      "           -2.6238,  -0.0889,   0.2163,   7.0052,   3.1609,  -1.6529,   0.5309,\n",
      "           -6.0646,  -1.9377,  -0.2695,  -9.5303,  -0.9818,   0.0500,   0.0350,\n",
      "            1.7477,   1.8275,   7.8607,   5.7925,  -0.5259,   0.4614,   1.9476,\n",
      "            5.5303,   1.0444,   6.4000,   3.0522,   5.2865,  -2.8123,  -0.2817,\n",
      "            4.1774,   0.4127,   1.4004,   3.0946,  -1.4502,  -2.3236,  -3.1005,\n",
      "            1.7757,   6.9020,   2.5628,  -0.9078,  -0.6352,  -0.3162,  -1.5521,\n",
      "           -0.9123,  -0.7160,  -0.5196,   6.1742,   1.0420,  -5.0624,   4.1924,\n",
      "            2.8714,   0.2958,   3.4773,   0.2079,  -2.6147,  -0.6461,  -0.3077,\n",
      "           -0.6089,  -1.0145,   3.9303,   4.4453,   4.7025,  -0.5703,   1.4242,\n",
      "            1.2222,  -4.3555,  -3.7755,   1.3323,  -2.8181,  -2.4056,   3.7640,\n",
      "            5.4140,   4.6849,   4.8486,  -1.0506,  -1.2769,   2.5089,  -3.0954,\n",
      "           -0.2079,  -3.1803,   3.6367,   1.4784,   2.0162,  -5.5584,   1.4731,\n",
      "           -4.5382,  -3.5934,   0.6879,  -1.4625,   1.3650,   2.3466,   8.3224,\n",
      "            2.7388,   1.0682,  -3.6924,  -3.8727,   1.1518,   0.1424,   3.4464,\n",
      "            0.6870,  -1.8813,  -2.6162,  -0.3469,   3.2224,  -0.1673,  -2.6724,\n",
      "            5.3175,   5.5572,   4.8478,   0.3461,   2.4728,  -0.1467,   1.8288,\n",
      "           -4.1312,  -3.9874,   5.1224,   4.6908,   0.4128,  -1.3272,  -4.3134,\n",
      "           -4.4953,  -0.3406,  -0.3158,  -2.2909,  -2.7704,  -2.1863,  -2.7505,\n",
      "            2.2749,   0.1154,   0.6638,  -0.2462,   1.4793,  -3.5623,  -5.2891,\n",
      "           -6.3183,  -4.5195,  -0.7036,   3.2911,  -0.6730,   7.1203,   2.6701,\n",
      "            7.5542,  -3.5276,  -2.5698,  -2.0433,  -2.4014,   4.4856,   3.6575,\n",
      "           -5.2191,  -4.5097,  -5.4352,   3.8649,   5.2203,   5.5207,  -1.5081,\n",
      "           -0.4442,  -0.3058,  -0.2168,  -0.1886,   1.3073,  -1.8523,  -1.4453,\n",
      "            3.5533,   0.2265,   1.4128,   4.4069,  -4.8953,  -1.2964,  -1.3950,\n",
      "           -1.1574,   1.0230,  -2.1670,  -2.5821,   0.5471,   2.9922,   4.2310,\n",
      "            2.9915,   3.3620,   5.0848,  -1.5406,   0.0580]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[111]])\n",
      "pred 111\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[ 1.4587e+01, -6.2590e+00, -7.0133e+00, -4.5945e+00, -2.1228e+00,\n",
      "          -2.0164e+00,  2.8977e+00,  4.4497e+00,  1.5035e+00, -7.3383e+00,\n",
      "           3.0558e+00, -4.6875e+00, -1.6569e+00,  3.0144e+00,  8.5565e-01,\n",
      "           3.6537e+00,  2.7159e+00,  5.8412e+00, -1.9672e+00,  9.2228e+00,\n",
      "          -4.6567e+00, -1.9548e+00,  3.1167e+00,  2.1556e+00, -3.4401e+00,\n",
      "          -3.2125e+00, -3.5187e+00, -1.4734e+00, -5.1776e+00, -5.0880e-01,\n",
      "          -4.6343e-01, -2.5540e+00, -1.7988e+00,  7.7968e-02,  3.8071e+00,\n",
      "          -5.8254e+00,  7.5250e+00,  4.1379e+00, -1.7813e+00,  1.0596e+00,\n",
      "          -1.5415e+00, -6.2343e+00,  3.0481e+00,  4.8129e+00,  2.5263e+00,\n",
      "           7.1380e-01,  4.7291e+00, -1.8931e+00, -1.0305e+00, -2.9364e+00,\n",
      "           1.0985e+00,  1.2421e+00, -2.1052e+00,  2.9500e+00, -6.7326e+00,\n",
      "          -2.9501e+00, -9.6378e-01,  2.8757e+00,  5.0686e+00, -2.0056e+00,\n",
      "          -1.2799e+00, -8.4057e-01, -6.2027e+00, -7.2041e+00, -8.1655e+00,\n",
      "          -9.9491e-01, -4.3774e-01, -3.7556e-01, -6.8008e+00,  4.3379e+00,\n",
      "          -5.5091e+00, -3.3357e+00, -5.1753e+00, -2.3950e+00,  5.4615e-01,\n",
      "          -1.8283e+00, -1.8690e+00, -3.6169e+00, -6.3928e+00,  1.2163e+00,\n",
      "           1.3397e+00,  1.0002e+00, -8.0385e-01, -1.1926e+00,  1.4220e+00,\n",
      "          -5.7052e+00, -3.1243e+00, -1.5904e+00, -5.5493e+00, -9.0091e+00,\n",
      "          -2.5483e+00,  1.7852e+00,  1.7742e+00, -1.8170e-01, -3.7853e-01,\n",
      "          -6.9689e-01, -1.2417e-02,  3.3736e-01, -1.8661e+00, -1.8549e+00,\n",
      "          -3.7446e+00, -4.0093e+00, -1.5128e-01, -3.1911e+00, -1.0148e+00,\n",
      "          -7.5024e+00, -2.9910e+00, -2.4890e+00, -1.8017e+00, -1.6854e+00,\n",
      "           5.3177e+00,  4.1027e+00,  3.4554e+00,  2.1336e+00, -3.6798e+00,\n",
      "          -5.9769e+00,  1.3685e+00,  1.8349e-02,  7.4558e-01, -4.9201e+00,\n",
      "          -4.5746e+00, -4.4082e+00, -3.2541e+00,  4.1807e+00, -8.9754e+00,\n",
      "           5.1311e-01, -3.0672e+00, -3.5150e+00,  1.1808e-01, -6.6350e+00,\n",
      "          -2.3741e+00, -6.4701e-02,  3.0704e+00,  6.6952e-01, -1.9005e+00,\n",
      "           1.2227e+00,  5.8969e+00,  5.7678e+00,  1.4488e+00, -8.1711e+00,\n",
      "          -4.8974e+00,  3.5085e-01, -6.0076e+00, -6.5640e+00, -6.8737e+00,\n",
      "          -5.8249e+00, -7.1545e+00, -5.0804e+00, -3.4634e+00, -3.0364e+00,\n",
      "          -8.4937e+00,  1.5891e+00, -4.1255e+00, -5.4845e+00, -2.5647e+00,\n",
      "          -1.5796e+00, -2.5615e+00,  1.9330e+00,  1.7203e+00, -2.1094e+00,\n",
      "          -2.9960e+00,  3.9108e+00, -4.9514e+00, -3.9816e+00, -4.0452e+00,\n",
      "          -4.0906e+00,  3.2999e-01, -1.3790e+00, -2.2692e+00, -4.3318e+00,\n",
      "           3.6853e+00, -4.2569e+00,  6.3476e-01,  8.0069e-01, -7.3362e+00,\n",
      "          -9.8731e+00, -5.3301e+00, -9.7377e+00, -5.1327e+00, -5.0093e+00,\n",
      "          -5.3081e+00, -2.1831e+00,  2.8726e+00, -7.1812e+00, -3.5724e+00,\n",
      "          -3.4174e+00, -1.0692e+01, -5.8264e+00, -6.4556e-01, -8.6923e+00,\n",
      "           1.4193e-01, -2.1615e+00, -2.5696e+00, -3.3165e+00, -5.8742e+00,\n",
      "          -8.7045e-01, -3.5794e+00, -4.5094e+00,  5.0464e-01, -3.7090e+00,\n",
      "          -2.5393e+00]]], grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[0]])\n",
      "pred 0\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[ 1.2514e+01, -6.0997e+00, -7.0902e+00,  6.3135e-01,  8.1671e+00,\n",
      "           2.2417e+00,  2.6356e+00,  2.4931e+00,  4.0842e+00, -2.0151e+00,\n",
      "           9.9487e-01,  1.3020e+00, -3.1288e+00, -2.4626e+00,  2.8648e+00,\n",
      "           2.4241e+00,  3.8862e-01,  2.5181e+00, -4.8970e+00,  7.7839e+00,\n",
      "          -8.0778e+00, -3.6465e+00,  1.8375e+00,  3.2422e+00,  4.3612e+00,\n",
      "           2.5774e+00, -7.7444e+00, -3.5991e+00,  7.2293e-01,  2.4182e+00,\n",
      "          -2.4080e+00, -6.4376e-01,  3.0939e-01, -3.1100e+00,  2.6493e-01,\n",
      "          -9.1129e+00,  8.2636e-01,  6.7689e-01, -4.5273e+00, -1.9622e+00,\n",
      "          -4.7313e+00, -9.9533e+00,  4.0381e+00,  1.2743e+00,  3.6622e+00,\n",
      "          -2.4764e+00,  2.9554e-01,  6.7401e+00,  6.4571e+00, -1.0522e+01,\n",
      "          -5.3106e-01,  4.1295e+00, -5.5790e+00,  1.4512e+00, -2.8290e+00,\n",
      "           6.6480e+00, -3.9951e+00,  1.9600e-01, -1.8358e-02, -4.2904e+00,\n",
      "           1.7880e+00, -4.1552e+00, -1.0651e+00, -7.1621e+00, -9.7976e+00,\n",
      "          -4.0200e+00, -7.4888e+00, -5.0000e+00, -2.0267e+00, -2.3222e-01,\n",
      "          -1.0377e+01, -9.6092e+00,  1.1319e+00, -2.7392e+00, -8.1083e-02,\n",
      "          -4.3100e+00, -3.9102e+00, -4.1648e+00, -9.2560e+00, -3.9409e-01,\n",
      "          -3.9749e+00, -4.5975e+00, -1.8803e-01, -3.9925e+00, -1.5813e+00,\n",
      "          -2.9637e+00,  6.9370e-01, -1.4129e+00, -4.6273e+00, -1.0296e+01,\n",
      "          -3.8400e+00, -3.4137e+00, -3.3137e+00, -8.0184e+00, -4.5882e+00,\n",
      "          -4.7748e+00, -5.1520e+00, -2.1813e+00,  2.6170e+00, -1.5088e+00,\n",
      "          -3.7331e+00, -7.6010e+00, -4.9789e+00, -6.7541e+00,  1.3243e+00,\n",
      "          -2.0428e+00, -1.2182e+00, -4.4621e-02, -1.1809e+00, -6.3158e-01,\n",
      "           3.5703e-01, -3.4264e+00, -8.0017e-01, -3.1179e+00, -4.5257e+00,\n",
      "          -6.9216e+00,  1.1159e+00, -2.4792e+00, -2.4802e+00, -8.1011e+00,\n",
      "          -8.1387e+00, -4.9971e+00, -5.8522e+00,  4.4959e+00, -1.3016e+00,\n",
      "           2.9250e+00, -8.1173e+00, -8.2735e+00, -2.3550e+00, -3.5066e+00,\n",
      "          -6.6993e+00, -2.1530e+00, -6.6065e+00,  2.9080e+00,  1.5808e+00,\n",
      "          -3.5534e+00,  4.1800e+00,  3.6629e+00,  3.8336e+00, -8.8035e+00,\n",
      "          -4.6088e+00,  7.3398e+00, -8.9659e+00, -5.9490e-01, -8.5711e-01,\n",
      "          -5.2047e-04, -1.0185e+00, -3.7575e+00, -7.0334e+00, -7.0088e+00,\n",
      "          -7.7163e+00,  2.7689e+00,  7.7705e-01, -6.8580e+00,  1.9134e+00,\n",
      "          -2.3416e+00, -4.0692e+00,  7.0649e+00,  3.1285e+00, -6.2703e+00,\n",
      "          -2.5182e-01,  1.7431e+00, -5.7344e-01, -1.6285e+00, -1.8945e+00,\n",
      "          -2.1877e+00,  5.7972e-01, -1.0618e+00,  1.7245e+00, -1.6304e+00,\n",
      "           2.1378e+00, -6.1269e+00, -1.3611e+00, -6.7835e-01, -5.5586e+00,\n",
      "          -9.1818e+00, -5.3750e+00, -8.9562e+00, -5.4780e+00, -2.5120e+00,\n",
      "          -1.3572e+00, -1.8916e+00, -1.7563e+00, -5.7143e+00, -1.0502e+01,\n",
      "          -6.6770e+00, -1.5310e+01, -8.8187e+00, -3.5779e+00, -3.1476e+00,\n",
      "           1.2879e+00, -7.2282e+00, -7.1742e+00, -1.9427e+00, -4.9377e+00,\n",
      "          -5.0484e+00, -6.0932e+00, -2.8403e+00,  1.5171e+00, -9.6412e-01,\n",
      "          -2.3184e+00]]], grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[0]])\n",
      "pred 0\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[ 10.5220,  -6.0525,  -7.3641,   8.3606,  15.5293,   5.4805,   2.7163,\n",
      "            1.0185,   2.4880,   1.3354,   2.1846,  -1.3781,  -2.6580,  -3.1701,\n",
      "           -0.4335,   6.0306,   0.3247,   4.2854,  -4.3843,   3.0211,  -7.4631,\n",
      "           -1.6737,   7.2173,  -3.0650,  -3.9000,   1.0508,  -6.7337,  -7.9849,\n",
      "            3.2687,   2.0310,  -8.4757,  -4.4173,   3.0041,  -2.4288,   1.1946,\n",
      "          -11.4717,  -2.6561,  -3.3203,  -5.9255,  -5.8216,  -6.1476, -12.2741,\n",
      "           -3.7320,  -1.1674,   1.2127,  -2.9628,  -3.1213,   6.5323,   3.1811,\n",
      "          -11.7808,   2.2135,   6.2956,  -5.1344,   1.2577,   0.1262,   3.9687,\n",
      "           -0.5741,  -3.1919,   0.3868,  -5.3029,   2.2685,  -7.0701,  -1.7017,\n",
      "           -8.5813,  -3.9998,  -3.1101, -10.7699,  -4.4183,  -0.7294,  -1.7433,\n",
      "           -6.7472,  -2.8450,  -6.4511,  -2.5807,   1.2499,  -6.3909,  -6.5406,\n",
      "          -10.1007,  -6.6293,  -1.1933,  -7.3785,  -7.9466,  -1.9687,  -8.8006,\n",
      "           -5.4556,  -2.9311,  -2.2173,  -0.0268,  -5.9657,  -5.7236,  -4.3080,\n",
      "           -9.2742,  -9.3366,  -9.5064,  -5.6105,  -6.3348,  -2.8372,   1.8079,\n",
      "            6.7718,   2.2222,  -6.1515,  -5.4897,  -1.3089,  -0.7727,  -4.0242,\n",
      "           -0.7560,  -0.1209,  -0.2516,  -0.3747,  -4.7380,  -1.8953,  -6.6942,\n",
      "           -1.9876,  -6.4876,  -3.0512,  -5.6360,  -0.8391,  -2.3333,  -2.7303,\n",
      "           -3.6340,  -4.3746,  -2.4692,  -1.8765,  -0.8821,  -0.3799,   2.7996,\n",
      "           -8.1800,  -8.3611,  -1.7099,  -5.2114, -11.9298,  -2.1040,  -6.8837,\n",
      "            3.8166,   2.7072,  -6.6003,   0.5271,   4.2876,   1.3629,  -7.9660,\n",
      "           -2.5443,   5.5553,  -6.2759,  -1.0039,  -0.5923,  -0.2833,  -1.0496,\n",
      "          -10.4336,  -3.2345,  -3.3773,  -8.5789,  -7.0189,   4.9141,  -1.9650,\n",
      "            2.9073,  -2.0853,  -8.8378,   3.0733,   3.3062,  -8.8306,  -0.5507,\n",
      "           -0.4744,  -4.8091,  -2.0253,  -2.5649,  -1.9539,  -4.6396,  -3.5509,\n",
      "           -0.7157,   2.7145,   1.4375,  -2.0026,  -4.1751,  -3.9611,  -3.4877,\n",
      "           -8.7298,  -5.1336,  -8.5683,  -5.4893,  -6.1048,  -3.9818,  -0.0566,\n",
      "           -2.0238,  -5.4807, -12.2047,  -7.5333,  -7.2565, -10.1319,  -4.7334,\n",
      "           -1.4310,  -2.7821,   0.4659,   0.3902,  -3.7034,  -6.8826,  -8.3026,\n",
      "           -7.9056,  -8.5973,  -2.8969,   1.2284,  -1.1667]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[4]])\n",
      "pred 4\n",
      "X torch.Size([1, 1, 32])\n",
      "y_shape torch.Size([1, 1, 201])\n",
      "tensor([[[ 3.7553e-01, -1.6386e+00, -2.2572e+00,  2.0685e+01,  9.2410e+00,\n",
      "           1.9815e+00,  3.2471e-01, -5.3629e+00,  6.8435e-01,  6.1242e+00,\n",
      "           4.6421e-03, -3.9413e+00,  1.3363e+00, -1.1142e+01,  5.8336e-01,\n",
      "           3.0570e+00,  2.2601e+00, -1.5934e-01, -6.8571e+00, -5.4783e+00,\n",
      "          -2.0947e+00, -6.0152e+00,  3.1159e+00, -9.5144e+00, -3.6062e+00,\n",
      "           5.9763e+00, -4.5659e-01, -1.1772e+01,  1.1513e+00,  4.5265e+00,\n",
      "          -9.4621e+00, -4.4524e+00,  5.9372e+00, -6.3001e+00, -4.9178e+00,\n",
      "          -1.9671e+00, -3.1553e+00,  4.4037e-01,  4.4132e-01, -6.3586e+00,\n",
      "          -8.1980e+00, -2.7499e+00, -7.5357e+00, -2.6024e+00, -1.7240e+00,\n",
      "           3.0763e-01, -6.9034e+00,  4.1437e+00,  5.3339e+00, -5.9017e-01,\n",
      "          -3.6664e+00,  8.3616e+00, -8.8635e+00, -1.8158e+00,  7.2618e+00,\n",
      "           2.5168e+00,  1.0391e+00, -6.4222e+00, -2.0584e-01, -1.8635e+00,\n",
      "           5.1783e-01, -5.7681e+00,  2.6435e+00,  4.6063e-01, -2.1213e-01,\n",
      "          -4.2708e-02, -5.7873e+00,  2.5858e+00,  7.6240e-01, -6.4423e+00,\n",
      "           1.0693e+00, -2.7116e-01, -1.3925e+00, -6.8607e-02,  2.9185e+00,\n",
      "          -5.2745e+00, -5.5187e+00, -8.9824e+00, -3.0735e+00, -8.2164e-01,\n",
      "          -3.1558e+00, -3.2513e+00,  1.1034e+00, -8.2491e+00, -6.4929e+00,\n",
      "          -7.1230e-01,  1.6104e+00,  1.6220e+00, -1.3490e+00, -6.4488e-02,\n",
      "          -4.6876e+00, -7.4925e+00, -7.7067e+00, -5.0356e+00, -6.8972e+00,\n",
      "          -7.6854e+00,  3.9265e-01, -2.2166e+00,  6.7337e+00,  3.6017e+00,\n",
      "          -4.8010e+00, -1.3955e+00, -2.0649e+00,  1.5326e-01, -3.1791e+00,\n",
      "          -6.5737e-01, -1.7719e+00, -3.4854e-01, -4.1152e-01, -5.4249e-02,\n",
      "          -4.6939e+00, -7.0273e+00, -3.8395e+00, -4.1686e+00,  2.8123e-01,\n",
      "          -3.6268e+00,  2.1265e+00, -2.5962e+00,  1.6093e+00, -3.6770e-01,\n",
      "          -1.1778e-01, -4.9889e-01, -1.7152e-01, -7.8392e+00,  4.5099e+00,\n",
      "           3.6514e+00, -4.2650e-01,  4.2991e-01,  5.9067e-02, -1.3677e+00,\n",
      "          -4.9856e+00, -2.4315e+00, -1.0136e+01, -1.8474e+00, -2.2533e+00,\n",
      "          -5.7609e+00, -9.8670e-01,  7.0732e-02, -2.7397e+00, -1.6677e+00,\n",
      "           9.1491e-02,  1.2359e+00, -2.5631e+00,  2.0747e+00,  2.5673e+00,\n",
      "           2.4194e+00,  2.5089e+00, -4.9013e+00,  9.7110e-01,  2.8087e-01,\n",
      "          -1.4084e+00, -1.2528e+01, -6.4800e-02,  1.1149e+00,  1.9328e+00,\n",
      "          -2.1553e+00, -7.6249e+00,  3.2724e+00,  1.5149e-02, -3.2622e+00,\n",
      "          -2.3828e+00,  9.2921e-01, -7.9652e+00, -2.3555e-01,  3.8777e-02,\n",
      "          -1.5153e-01, -2.4353e+00, -2.1307e+00,  1.3876e+00,  6.6250e+00,\n",
      "          -1.7272e+00,  4.8154e-01, -4.7585e+00, -4.6571e+00, -3.2757e-02,\n",
      "          -1.9898e+00,  2.2019e+00, -1.5194e+00,  1.7562e+00, -5.2364e+00,\n",
      "          -3.1385e+00,  1.8153e+00, -7.1388e+00, -7.2700e-01, -9.0007e+00,\n",
      "           4.6203e+00,  7.5299e+00, -2.5022e+00, -1.7119e-01,  3.7481e+00,\n",
      "          -1.5220e+00, -1.8980e+00, -1.4417e+00,  1.8020e+00,  3.7794e+00,\n",
      "          -1.1452e-01, -7.3388e+00, -5.9661e+00, -6.0183e+00,  3.1834e+00,\n",
      "           3.0553e+00]]], grad_fn=<PermuteBackward0>)\n",
      "dec_X_shape torch.Size([1, 1])\n",
      "dec_X tensor([[3]])\n",
      "pred 3\n",
      "i'm home . => je suis chez aucune <unk> <unk> ., bleu 0.574\n"
     ]
    }
   ],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "#     print('eng',eng,'fra',fra)\n",
    "    translation, attention_weight_seq = predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device)\n",
    "    print(f'{eng} => {translation}, bleu {bleu(translation, fra, k=2):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccfbde09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2,3],[3,2,5],[7,3,8]]).argmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dda7442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df391c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
